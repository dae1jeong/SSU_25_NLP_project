{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzE0ZwIN5n1R"
      },
      "outputs": [],
      "source": [
        "pip install ragas datasets openai evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness, answer_relevance, context_precision, context_recall\n",
        "# ragas.llms import RagasLLM 대신 문자열 이름으로 모델을 지정하면 Ragas가 자동으로 OpenAI 설정을 처리합니다.\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 0. 설정 및 환경 변수 확인\n",
        "# ----------------------------------------------------\n",
        "# OpenAI API 키가 환경 변수에 설정되어 있는지 확인\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    # 예시를 위해 임시로 설정하거나 사용자에게 환경 변수 설정을 요구할 수 있습니다.\n",
        "    # 실제 사용 시에는 터미널에서 export OPENAI_API_KEY='...' 와 같이 설정해야 합니다.\n",
        "    print(\"WARNING: OPENAI_API_KEY 환경 변수가 설정되지 않았습니다. 테스트를 위해 임시로 'dummy'를 사용하지만, 실제 API 호출은 실패합니다.\")\n",
        "    # raise ValueError(\"OPENAI_API_KEY 환경 변수를 설정해야 합니다.\") # 실제 사용 시에는 이 라인을 활성화해야 합니다.\n",
        "\n",
        "# GPT-4o-mini 모델 지정\n",
        "GENERATOR_MODEL = \"gpt-4o-mini\"\n",
        "CRITIC_MODEL = \"gpt-4o-mini\"\n",
        "CONTEXT_FILE = \"contexts.jsonl\"\n",
        "TEST_SIZE = 10  # 생성할 질문-답변 쌍의 개수 (테스트 목적)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. JSONL 파일에서 Contexts 로드 및 Dataset으로 변환\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def load_jsonl_to_list(file_path):\n",
        "    \"\"\"JSONL 파일을 읽어 딕셔너리 리스트로 반환\"\"\"\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line.strip()))\n",
        "    return data\n",
        "\n",
        "def prepare_contexts_dataset():\n",
        "    \"\"\"Contexts.jsonl 파일을 로드하거나 생성하여 Ragas 입력 Dataset 형식으로 변환\"\"\"\n",
        "    try:\n",
        "        context_data_list = load_jsonl_to_list(CONTEXT_FILE)\n",
        "        print(f\"Loaded {len(context_data_list)} contexts from {CONTEXT_FILE}.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {CONTEXT_FILE} 파일을 찾을 수 없습니다. 예시 파일을 생성합니다.\")\n",
        "        # 파일이 없을 경우 예시 데이터 생성 및 저장\n",
        "        sample_data = [\n",
        "            {\"text\": \"지구는 태양계의 행성 중 하나이며, 생명체가 서식하는 유일한 곳이다.\", \"doc_id\": \"doc_1\", \"category\": \"space\"},\n",
        "            {\"text\": \"물은 수소 원자 두 개와 산소 원자 하나로 구성되어 있으며, 100°C에서 끓는다.\", \"doc_2\": \"doc_2\", \"category\": \"chemistry\"},\n",
        "            {\"text\": \"BERT는 구글이 개발한 언어 모델로, 양방향 학습을 통해 문맥 이해 능력을 향상시켰다.\", \"doc_3\": \"doc_3\", \"category\": \"ai\"},\n",
        "        ]\n",
        "        with open(CONTEXT_FILE, 'w', encoding='utf-8') as f:\n",
        "            for item in sample_data:\n",
        "                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "        context_data_list = sample_data\n",
        "        print(f\"Created sample {CONTEXT_FILE} with {len(context_data_list)} entries.\")\n",
        "\n",
        "    # Ragas 입력을 위한 Dataset 형식으로 변환 (각 텍스트 청크를 리스트로 감싸야 함)\n",
        "    synthetic_contexts = Dataset.from_list([\n",
        "        {'contexts': [item['text']],\n",
        "         # 메타데이터를 활용하여 필터링 평가에 사용할 수 있도록 JSON 문자열로 저장\n",
        "         'metadata': json.dumps({'doc_id': item.get('doc_id'), 'category': item.get('category')})}\n",
        "        for item in context_data_list\n",
        "    ])\n",
        "    return synthetic_contexts\n",
        "\n",
        "synthetic_contexts = prepare_contexts_dataset()\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. 합성 데이터셋 (테스트셋) 생성\n",
        "# ----------------------------------------------------\n",
        "\n",
        "print(\"\\n--- Starting synthetic testset generation ---\")\n",
        "\n",
        "generator = TestsetGenerator.from_llm(\n",
        "    generator_llm=GENERATOR_MODEL,\n",
        "    critic_llm=CRITIC_MODEL,\n",
        "    embeddings=\"openai\" # 임베딩 모델도 OpenAI API를 사용\n",
        ")\n",
        "\n",
        "# 생성할 질문 유형 및 개수 설정\n",
        "test_distributions = {\n",
        "    simple: 0.5,           # 단순 질문\n",
        "    reasoning: 0.3,        # 추론 질문\n",
        "    multi_context: 0.2     # 다중 Context 질문\n",
        "}\n",
        "\n",
        "# 합성 데이터셋 생성\n",
        "# 이 단계에서 LLM API 호출이 발생하며, 비용이 발생합니다.\n",
        "test_set = generator.generate_with_text_chunks(\n",
        "    synthetic_contexts,\n",
        "    test_size=TEST_SIZE,\n",
        "    distributions=test_distributions,\n",
        "    raise_exceptions=False # 오류 발생 시 건너뛰기 설정\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Synthetic Testset Generated ({len(test_set)} samples) ---\")\n",
        "print(test_set.to_pandas())\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 3. RAG 시스템으로 질문에 답변 (⭐ 사용자 정의 필수)\n",
        "# ----------------------------------------------------\n",
        "# 이 부분은 실제 RAG 시스템을 호출하여 답변을 얻는 과정입니다.\n",
        "# 평가를 위해 RAG 시스템이 생성한 답변('answer')과 검색한 Contexts('contexts')가 필요합니다.\n",
        "\n",
        "def generate_rag_answers(dataset):\n",
        "    \"\"\"\n",
        "    (Placeholder) 실제 RAG 시스템을 호출하여 답변(answer)과 검색된 Contexts를 반환하는 함수\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Simulating RAG Generation ---\")\n",
        "\n",
        "    answers = []\n",
        "    retrieved_contexts = []\n",
        "\n",
        "    for item in dataset:\n",
        "        # 1. (실제 구현) item['question']을 RAG 시스템에 입력하고 답변을 얻습니다.\n",
        "        # answer, retrieved_context = your_rag_system(item['question'])\n",
        "\n",
        "        # 2. (예시) 정확도 100% 시뮬레이션을 위해, 정답(ground_truth)과 Contexts를 재사용합니다.\n",
        "        answers.append(item['ground_truth'])\n",
        "        retrieved_contexts.append(item['contexts'])\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'question': dataset['question'],\n",
        "        'answer': answers,                        # RAG 시스템이 생성한 답변\n",
        "        'contexts': retrieved_contexts,           # RAG 시스템이 검색한 Contexts (리스트여야 함)\n",
        "        'ground_truths': dataset['ground_truth']  # 합성 데이터셋의 정답\n",
        "    })\n",
        "\n",
        "# RAG 시스템의 답변 결과가 포함된 데이터셋\n",
        "rag_evaluation_data = generate_rag_answers(test_set)\n",
        "print(\"\\n--- RAG Evaluation Data Prepared ---\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. Ragas 지표를 이용한 평가 수행\n",
        "# ----------------------------------------------------\n",
        "\n",
        "print(\"\\n--- Starting Ragas Evaluation ---\")\n",
        "\n",
        "# Ragas 평가 지표 정의\n",
        "ragas_metrics = [\n",
        "    faithfulness,        # 충실도: 답변이 검색된 Contexts에 기반하는 정도\n",
        "    answer_relevance,    # 답변 관련성: 답변이 질문과 관련이 있는 정도\n",
        "    context_precision,   # Context 정확도: 검색된 Contexts가 질문에 얼마나 정확한가\n",
        "    context_recall       # Context 재현율: 검색된 Contexts가 정답 정보를 얼마나 잘 포함하는가\n",
        "]\n",
        "\n",
        "# 평가 수행 (LLM API 호출 발생 및 비용 발생)\n",
        "results = evaluate(\n",
        "    rag_evaluation_data,\n",
        "    metrics=ragas_metrics,\n",
        "    llm=GENERATOR_MODEL,\n",
        "    embeddings=\"openai\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- FINAL RAG EVALUATION RESULTS (Mean Scores) ---\")\n",
        "print(results)\n",
        "# 결과 딕셔너리를 Pandas DataFrame으로 변환 후 평균 점수 출력\n",
        "mean_scores = results.to_pandas().mean(numeric_only=True)\n",
        "print(mean_scores.to_markdown())"
      ],
      "metadata": {
        "id": "i3JOaX_y5tgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}