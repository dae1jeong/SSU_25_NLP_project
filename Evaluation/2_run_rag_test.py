import json
import random
import sys
import os
from tqdm import tqdm

from dataclasses import dataclass # ğŸ’¡ dataclasses ì„í¬íŠ¸ ì¶”ê°€
from typing import List, Dict     # ğŸ’¡ typing ì„í¬íŠ¸ ì¶”ê°€ (List, Dict ì‚¬ìš©ì„ ìœ„í•´)

# RAG íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
# RAG.rag_pipeline_chunked.py íŒŒì¼ì—ì„œ ì§ì ‘ ì„í¬íŠ¸í•  ìˆ˜ ì—†ëŠ” ê²½ìš°, ì•„ë˜ í´ë˜ìŠ¤ë“¤ì„ ì—¬ê¸°ì— ì •ì˜í•©ë‹ˆë‹¤.
from RAG.rag_pipeline_chunked import RAGPipeline, call_openai_api 


# -----------------------------------------------
# ğŸ’¡ [í•„ìˆ˜ ì¶”ê°€] ChunkDocument ì¬ì •ì˜
# -----------------------------------------------
@dataclass
class ChunkDocument:
    id: str
    text: str
    meta: Dict
    tokens: List[str]


# -----------------------------------------------
# ğŸ’¡ [í•„ìˆ˜ ì¶”ê°€] EvaluationResult ì •ì˜
# -----------------------------------------------
@dataclass
class EvaluationResult:
    """RAG ì‹œìŠ¤í…œ í‰ê°€ì— í•„ìš”í•œ ëª¨ë“  ê²°ê³¼ë¥¼ ë‹´ëŠ” êµ¬ì¡°"""
    query: str                       
    model_answer: str                
    retrieved_chunks: List[ChunkDocument] # ğŸ’¡ ChunkDocument ì‚¬ìš©
    context_texts: List[str]         
    is_rag_flow: bool


def run_test():
    data_path = "Evaluation/data/ragas_qa_dataset_remove2.jsonl"
    if not os.path.exists(data_path):
        print("âŒ ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. 1ë²ˆ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # 1. ë°ì´í„°ì…‹ ë¡œë“œ
    with open(data_path, "r", encoding="utf-8") as f:
        all_data = [json.loads(line) for line in f if line.strip()]
    
    # 2. 100ê°œ ëœë¤ ìƒ˜í”Œë§ (ë¹„ìš© ì ˆì•½)
    sample_size = min(100, len(all_data))
    test_samples = random.sample(all_data, sample_size)
    
    print(f"ğŸ§ª {sample_size}ê°œ ë¬¸ì œë¡œ RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("   (ì°¸ê³ : rag_pipeline.pyì— ì„¤ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤)")

    # 3. RAG ì—”ì§„ ë¡œë”©
    rag = RAGPipeline()
    results = []
    
    # 4. ë¬¸ì œ í’€ê¸°
    for item in tqdm(test_samples):
        question = item['question']
        ground_truth = item['ground_truth']
        # ğŸ’¡ Recall/MRR/RRF í‰ê°€ë¥¼ ìœ„í•´ ground_truth_chunk_idë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # ì´ í•„ë“œê°€ ì—†ìœ¼ë©´ Recall/MRR/RRFëŠ” ê³„ì‚° ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
        ground_truth_chunk_id = item.get('ground_truth_chunk_id')
        
        # ì±—ë´‡ì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
        try:
            # ğŸ’¡ í‰ê°€ ì „ìš© í•¨ìˆ˜ í˜¸ì¶œ
            eval_result: EvaluationResult = rag.answer_with_llm_EVAL(
                question, 
                llm_call=call_openai_api
            )
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ EvaluationResult í˜•íƒœë¡œ ì €ì¥
            eval_result = EvaluationResult(
                query=question,
                model_answer=f"ì—ëŸ¬ ë°œìƒ: {e}",
                retrieved_chunks=[],
                context_texts=[],
                is_rag_flow=False
            )
        
        # ğŸ’¡ EvaluationResult ê°ì²´ë¥¼ JSON ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        
        # ChunkDocument ê°ì²´ëŠ” JSONìœ¼ë¡œ ë°”ë¡œ ì €ì¥ì´ ì•ˆ ë˜ë¯€ë¡œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        retrieved_chunks_data = [
            {
                "id": d.id, 
                "text": d.text, 
                "meta": d.meta
            } 
            for d in eval_result.retrieved_chunks
        ]
        
        # ëª¨ë“  í‰ê°€ ì§€í‘œ ê³„ì‚°ì— í•„ìš”í•œ ì›ì²œ ë°ì´í„°ë¥¼ resultsì— ì €ì¥
        results.append({
            "question": question,
            "ground_truth": ground_truth,
            "ground_truth_chunk_id": ground_truth_chunk_id, # Recall/MRR/RRF ê¸°ì¤€ì 
            
            # --- ëª¨ë¸ì˜ ì¶œë ¥ ë° ê²€ìƒ‰ ê²°ê³¼ ---
            "model_answer": eval_result.model_answer,
            "is_rag_flow": eval_result.is_rag_flow,
            "retrieved_chunks": retrieved_chunks_data, 
            "context_texts": eval_result.context_texts, # RAGAs ì…ë ¥ìš© í…ìŠ¤íŠ¸ ëª©ë¡
            "latency_seconds": eval_result.latency_seconds # ğŸ’¡ ì—¬ê¸° ì¶”ê°€!
        })

    # 5. ê²°ê³¼ ì €ì¥
    # ğŸ’¡ ê²°ê³¼ íŒŒì¼ ì´ë¦„ì„ ëª…í™•í•˜ê²Œ ë³€ê²½í•©ë‹ˆë‹¤.
    output_filename = "Evaluation/data/rag_evaluation_results_full.json"
    with open(output_filename, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
        
    print(f"ì‹¤í–‰ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_filename}")

if __name__ == "__main__":
    run_test()