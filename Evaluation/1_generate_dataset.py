import os
import sys
import json
import sqlite3
import random
from openai import OpenAI
from dotenv import load_dotenv
from tqdm import tqdm

# 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ë¶€ëª¨ í´ë”ì˜ ëª¨ë“ˆì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# 2. .env ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), ".env"))

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
DB_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "ssu_chatbot_data.db")

def fetch_documents(limit=10):
    """DBì—ì„œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    
    # ê³µì§€ì‚¬í•­
    cur.execute("SELECT title, full_body_text FROM notices WHERE full_body_text IS NOT NULL AND length(full_body_text) > 50")
    notices = [f"[ê³µì§€] {t}\n{b}" for t, b in cur.fetchall()]
    
    # ê°•ì˜í‰
    cur.execute("SELECT subject_name, review_text FROM lecture_reviews WHERE review_text IS NOT NULL AND length(review_text) > 20")
    reviews = [f"[ê°•ì˜í‰] {s}\n{r}" for s, r in cur.fetchall()]
    
    conn.close()
    
    all_docs = notices + reviews
    random.shuffle(all_docs)
    
    print(f"ğŸ“Š DBì—ì„œ ì´ {len(all_docs)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. (ìµœëŒ€ {limit}ê°œ ì‚¬ìš©)")
    return all_docs[:limit]

def generate_qa_pair(text):
    """GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸-ì •ë‹µ ìŒ ìƒì„±"""
    prompt = f"""
    ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ì½ê³ , ì±—ë´‡ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë§Œí•œ ìì—°ìŠ¤ëŸ¬ìš´ 'ì§ˆë¬¸'ê³¼ ê·¸ì— ëŒ€í•œ 'ì •ë‹µ'ì„ 1ê°œë§Œ ìƒì„±í•´ì¤˜.
    ì •ë‹µì€ ë°˜ë“œì‹œ ì œê³µëœ í…ìŠ¤íŠ¸ì— ìˆëŠ” ë‚´ìš©ë§Œ ê¸°ë°˜í•´ì•¼ í•´.
    
    [í…ìŠ¤íŠ¸]:
    {text[:1000]}
    
    [ì¶œë ¥ í˜•ì‹ (JSON)]:
    {{
        "question": "ìƒì„±ëœ ì§ˆë¬¸",
        "ground_truth": "í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì •ë‹µ"
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", # âœ… ìƒì„±ì€ ì €ë ´í•œ mini ì‚¬ìš©
            messages=[{"role": "system", "content": "ë„ˆëŠ” ë°ì´í„°ì…‹ ìƒì„±ê¸°ì•¼. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ëŒ€ë‹µí•´."},
                      {"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception:
        return None

if __name__ == "__main__":
    docs = fetch_documents()
    dataset = []
    
    print(f"ğŸš€ gpt-4o-minië¡œ ë°ì´í„°ì…‹ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # âš ï¸ í…ŒìŠ¤íŠ¸í•  ë•ŒëŠ” range(len(docs)) ëŒ€ì‹  range(10)ìœ¼ë¡œ ì¤„ì—¬ì„œ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”!
    for i in tqdm(range(len(docs))):
        qa = generate_qa_pair(docs[i])
        if qa:
            dataset.append(qa)
            
        # 500ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ (ë‚ ë¦¼ ë°©ì§€)
        if len(dataset) % 500 == 0:
            with open("Evaluation/qa_dataset_intermediate.jsonl", "w", encoding="utf-8") as f:
                for item in dataset:
                    f.write(json.dumps(item, ensure_ascii=False) + "\n")

    # ìµœì¢… ì €ì¥
    with open("Evaluation/qa_dataset_5k.jsonl", "w", encoding="utf-8") as f:
        for item in dataset:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
            
    print(f"âœ… ìƒì„± ì™„ë£Œ! ì´ {len(dataset)}ê°œ ì €ì¥ë¨: Evaluation/qa_dataset_5k.jsonl")