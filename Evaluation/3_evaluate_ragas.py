
# í‰ê°€ ì‹œ í˜„ì¬ ì½”ë“œ ì²˜ëŸ¼ llm í‰ê°€ë„ ìœ ì§€í•˜ê³ , + ragas (ì •ëŸ‰ì  í‰ê°€ ì§€í‘œ)ë„ ì¶”ê°€í•˜ì.
# ragasëŠ” llmì„ ë„êµ¬ë¡œ í™œìš©í•˜ì—¬ ragë¥¼ ìë™í™”ëœ ì •ëŸ‰ì  í‰ê°€ ì§€í‘œë¡œ ì¸¡ì •í•¨.
# -> í˜„ì¬ ì½”ë“œë³´ë‹¤ ì¢€ ë” ì •ë°€í•œ í‰ê°€.ê°€ ê°€ëŠ¥.

# ì£¼ì˜ì‚¬í•­
# rag_pipeline.py íŒŒì¼ì—ì„œ 415~ Line ì£¼ì„ì„ í•´ì œí•´ì•¼í•¨.
# ì‘ì—…ì : ë°•ì±„ì€
"""
    ragas_input_path: run_rag_test.py ëŒë¦° ê²°ê³¼ë¬¼ ê²½ë¡œ
    ragas input í˜•íƒœ
        [
            {
                "question": "...",
                "answer": "...",
                "contexts": [{"id": "...", "text": "...", "meta": {...}}, ...],
                "ground_truths": ["..."]
            },
            ...
        ]
"""

import os
import json
import pandas as pd
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness, 
    answer_relevancy, 
    context_recall, 
    context_precision
)
from dotenv import load_dotenv
from tqdm import tqdm
from langchain_openai import ChatOpenAI, OpenAIEmbeddings 

# .env ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), ".env"))
# OpenAI í´ë¼ì´ì–¸íŠ¸ëŠ” LangChainì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ì§ì ‘ì ì¸ ì‚¬ìš©ì€ í•„ìš” ì—†ìŒ

# â­ 1. ìƒìˆ˜ ì •ì˜ ë° ì„¤ì • â­
RAGAS_INPUT_PATH = "/Evaluation/data/ragas_qa_dataset.jsonl" 
RAGAS_OUTPUT_CSV = "Evalation/data/ragas_scores.csv"

# â­ 2. Ragas í‰ê°€ì (LLM Judge) ëª…ì‹œì  ì„¤ì • â­
GPT_4O_LLM = ChatOpenAI(model="gpt-4o", temperature=0) # LLM Judge
OPENAI_EMBEDDINGS = OpenAIEmbeddings(model="text-embedding-3-small") # Embedding Model

# --------------------------------------------------------------------------
def load_full_json_data(file_path: str) -> list:
    """ë‹¨ì¼ JSON íŒŒì¼(ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    if not os.path.exists(file_path):
        print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return []

    print(f"-> JSON íŒŒì¼ ë¡œë“œ ì‹œì‘: {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        try:
            # ğŸ’¡ JSONLì´ ì•„ë‹Œ, ì „ì²´ íŒŒì¼ì„ í•œ ë²ˆì— ë¡œë“œ (ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸)
            data = json.load(f) 
        except json.JSONDecodeError as e:
            print(f"ì˜¤ë¥˜: JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ. ì˜¤ë¥˜: {e}")
            return []
    
    print(f"-> ì´ {len(data)}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ.")
    return data

def safe_save_csv(df: pd.DataFrame, file_path: str):
    """ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê³  CSV íŒŒì¼ì„ ì €ì¥í•˜ë©°, íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."""
    
    save_dir = os.path.dirname(file_path)
    base_filename = os.path.basename(file_path)

    # ë””ë ‰í† ë¦¬ ìƒì„±
    if save_dir and not os.path.exists(save_dir):
        os.makedirs(save_dir)
        print(f"-> ë””ë ‰í† ë¦¬ ìƒì„±: {save_dir}")
    
    # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ ë¡œì§ (ê°„ì†Œí™”)
    name, ext = os.path.splitext(base_filename)
    counter = 0
    filename_to_save = file_path
    
    while os.path.exists(filename_to_save):
        counter += 1
        new_filename = f"{name}_{counter}{ext}"
        filename_to_save = os.path.join(save_dir, new_filename)
    
    df.to_csv(filename_to_save, index=False)
    print(f"\nâœ… í‰ê°€ ê²°ê³¼ê°€ '{filename_to_save}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def evaluate_ragas_dataset_to_dataframe(ragas_input_data: list) -> pd.DataFrame:

    print("1. Ragas ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë§¤í•‘ ì‹œì‘...")
    
    # RAGAsê°€ ìš”êµ¬í•˜ëŠ” í•„ë“œ êµ¬ì¡°
    processed_data = {
        "question": [], 
        "answer": [], 
        "contexts": [],       # ğŸ’¡ List[str] í˜•íƒœì—¬ì•¼ í•¨
        "ground_truths": []   # ğŸ’¡ List[str] í˜•íƒœì—¬ì•¼ í•¨
    }
    
    for item in ragas_input_data:
        # ğŸ’¡ RAGAs ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ í•„ë“œ ë§¤í•‘
        processed_data["question"].append(item["question"])
        processed_data["answer"].append(item["model_answer"]) # 'answer' ëŒ€ì‹  'model_answer' ì‚¬ìš©

        # ğŸ’¡ contexts í•„ë“œëŠ” ì´ë¯¸ List[str] í˜•íƒœë¡œ ì €ì¥ëœ 'context_texts'ë¥¼ ì‚¬ìš©
        processed_data["contexts"].append(item["context_texts"])
        
        # ğŸ’¡ ground_truthsëŠ” RAGAsê°€ List[str]ì„ ìš”êµ¬í•˜ë¯€ë¡œ ë‹¨ì¼ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ìŒˆ
        processed_data["ground_truths"].append([item["ground_truth"]]) 
        
    dataset = Dataset.from_dict(processed_data)
    
    print(f"2. í‰ê°€ ëŒ€ìƒ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ. ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
    print("-" * 40)
    
    # 3. Ragas í‰ê°€ ì§€í‘œ ì„¤ì •
    metrics_to_evaluate = [
        faithfulness, answer_relevancy, context_recall, context_precision
    ]
    
    print("3. Ragas í‰ê°€ ì‹œì‘ (LLM Judge: GPT-4o ì‚¬ìš©)...")
    
    # â­ 4. Ragas í‰ê°€ ì‹¤í–‰ (LLMê³¼ Embeddings ëª¨ë¸ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬) â­
    result = evaluate(
        dataset=dataset,
        metrics=metrics_to_evaluate,
        llm=GPT_4O_LLM,
        embeddings=OPENAI_EMBEDDINGS 
    )
    
    print("4. í‰ê°€ ì™„ë£Œ.")
    print("-" * 40)

    # 5. ê²°ê³¼ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    result_df = result.to_pandas()
    
    print("5. ìµœì¢… ìš”ì•½ ì ìˆ˜:")
    print(result)
    print("\nâœ… ìƒ˜í”Œë³„ ìƒì„¸ í‰ê°€ ê²°ê³¼ DataFrame ë°˜í™˜.")
    
    return result.to_pandas()

# --------------------------------------------------------------------------

if __name__ == "__main__":
    
    # ğŸ’¡ RAGAs ì…ë ¥ ê²½ë¡œë¥¼ ì§ì „ì— ì €ì¥í•œ FULL JSON íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½
    # RAGAS_INPUT_PATH = "/Evaluation/data/ragas_qa_dataset.jsonl" 
    RAGAS_INPUT_PATH = "Evaluation/data/rag_evaluation_results_full.json" 
    
    # 1. JSON íŒŒì¼ ë¡œë“œ (í•¨ìˆ˜ ì´ë¦„ë„ load_full_json_dataë¡œ ë³€ê²½)
    ragas_data = load_full_json_data(RAGAS_INPUT_PATH)
    
    if not ragas_data:
        print("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ì–´ Ragas í‰ê°€ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        # 2. í‰ê°€ ì‹¤í–‰ ë° DataFrameìœ¼ë¡œ ê²°ê³¼ ì €ì¥
        print(f"ì´ {len(ragas_data)}ê°œ ìƒ˜í”Œë¡œ Ragas í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        evaluation_dataframe = evaluate_ragas_dataset_to_dataframe(ragas_data)
        
        # 3. ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ ë° ë””ë ‰í† ë¦¬ ìë™ ìƒì„±)
        safe_save_csv(evaluation_dataframe, RAGAS_OUTPUT_CSV)
        
        print("\n[ ìµœì¢… í‰ê°€ ê²°ê³¼ DataFrame ]")
        print(evaluation_dataframe.head())