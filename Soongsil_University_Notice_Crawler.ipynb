{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dae1jeong/SSU_25_NLP_project/blob/main/Soongsil_University_Notice_Crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv # CSV 저장을 위해 csv 모듈 추가\n",
        "import re\n",
        "from datetime import datetime # 날짜 처리를 위해 datetime 모듈 추가\n",
        "\n",
        "# 숭실대학교 스캐치(Scatch) 공지사항 페이지 URL을 설정합니다.\n",
        "# 실제 공지사항 목록 페이지 URL로 대체해야 합니다.\n",
        "# 예시 URL은 목록 페이지의 첫 번째 페이지를 가정합니다.\n",
        "BASE_URL = \"https://scatch.ssu.ac.kr/%ea%b3%b5%ec%a7%80%ec%82%ac%ed%95%ad/\" # <- 이 부분을 실제 URL로 변경해주세요.\n",
        "\n",
        "def fetch_notices(url):\n",
        "    \"\"\"\n",
        "    지정된 URL에서 공지사항 목록을 가져와 파싱하고 2025년 이후의 항목만 필터링합니다.\n",
        "    \"\"\"\n",
        "    # HTML 요청 시 발생할 수 있는 오류를 처리하기 위해 try-except 블록을 사용합니다.\n",
        "    try:\n",
        "        # 사용자 에이전트를 설정하여 봇 감지를 회피하고 정상적인 접근을 시도합니다.\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status() # HTTP 오류가 발생하면 예외를 발생시킵니다.\n",
        "\n",
        "        # 인코딩 문제 방지를 위해 응답 텍스트를 파싱합니다.\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"웹 페이지를 가져오는 중 오류가 발생했습니다: {e}\")\n",
        "        return []\n",
        "\n",
        "    # 공지사항 리스트를 담을 빈 리스트를 초기화합니다.\n",
        "    notices_data = []\n",
        "\n",
        "    # 각 공지사항 항목을 찾습니다. (<li> 태그의 하위 요소인 div.row...를 찾음)\n",
        "    notice_items = soup.find_all('div', class_=lambda c: c and 'row no-gutters align-items-center' in c)\n",
        "\n",
        "    for item in notice_items:\n",
        "        try:\n",
        "            # 1. 작성일 추출 및 필터링 (2025년 이후)\n",
        "            date_element = item.select_one('.notice_col1 .h2')\n",
        "            date = date_element.text.strip() if date_element else None\n",
        "\n",
        "            if date:\n",
        "                # 'YYYY.MM.DD' 형식에서 연도만 추출하여 필터링\n",
        "                try:\n",
        "                    # date[0:4]는 'YYYY' 부분입니다.\n",
        "                    year = int(date[0:4])\n",
        "                    if year < 2025:\n",
        "                        # 2025년 이전의 공지사항은 건너뜁니다.\n",
        "                        continue\n",
        "                except ValueError:\n",
        "                    # 날짜 형식이 잘못된 경우 건너뛰거나 'N/A'로 처리할 수 있습니다.\n",
        "                    print(f\"경고: 작성일 형식 오류로 필터링을 건너pro니다. (Date: {date})\")\n",
        "                    continue\n",
        "            else:\n",
        "                date = 'N/A'\n",
        "                continue # 날짜가 없는 항목은 처리하지 않음\n",
        "\n",
        "            # 2. 진행상황 추출\n",
        "            status_element = item.select_one('.notice_col2 .tag')\n",
        "            status = status_element.text.strip() if status_element else 'N/A'\n",
        "\n",
        "            # 3. 카테고리, 제목 및 링크 추출 (notice_col3 내부)\n",
        "            link_element = item.select_one('.notice_col3 a')\n",
        "            if link_element:\n",
        "                link_href = link_element['href'].strip()\n",
        "\n",
        "                category_element = link_element.select_one('.label')\n",
        "                category = category_element.text.strip() if category_element else 'N/A'\n",
        "\n",
        "                # 제목 추출\n",
        "                title_span = link_element.select_one('span[class*=\"d-inline-b\"].m-pt-5')\n",
        "                title = title_span.text.strip() if title_span else '제목 없음 (파싱 오류)'\n",
        "\n",
        "            else:\n",
        "                link_href, category, title = 'N/A', 'N/A', 'N/A'\n",
        "\n",
        "            # 4. 등록부서 추출 (notice_col4)\n",
        "            department_element = item.select_one('.notice_col4')\n",
        "            department = department_element.text.strip() if department_element else 'N/A'\n",
        "\n",
        "            # 5. 조회수 추출 (notice_col5)\n",
        "            views_element = item.select_one('.notice_col5')\n",
        "            # 콤마(,) 등 불필요한 문자를 제거하고 숫자만 추출하거나 원본 그대로 저장\n",
        "            views = views_element.text.strip() if views_element else 'N/A'\n",
        "\n",
        "            # 추출된 데이터를 딕셔너리 형태로 저장합니다.\n",
        "            notices_data.append({\n",
        "                '작성일': date,\n",
        "                '진행상황': status,\n",
        "                '카테고리': category,\n",
        "                '제목': title,\n",
        "                '링크': link_href,\n",
        "                '등록부서': department, # <-- 신규 항목\n",
        "                '조회수': views       # <-- 신규 항목\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"개별 공지사항 항목 파싱 중 오류 발생: {e}\")\n",
        "            continue\n",
        "\n",
        "    return notices_data\n",
        "\n",
        "def save_to_csv(data, filename=\"ssu_notices_2025_onwards.csv\"):\n",
        "    \"\"\"\n",
        "    크롤링한 데이터를 CSV 파일로 저장합니다.\n",
        "    \"\"\"\n",
        "    if not data:\n",
        "        print(\"저장할 데이터가 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # CSV 파일에 사용할 헤더(필드 이름)를 설정합니다. (신규 항목 포함)\n",
        "    fieldnames = ['작성일', '진행상황', '카테고리', '제목', '링크', '등록부서', '조회수']\n",
        "\n",
        "    # 파일을 쓰기 모드로 열고 인코딩은 'utf-8-sig'를 사용하여\n",
        "    # 엑셀에서 한글 깨짐을 방지합니다.\n",
        "    try:\n",
        "        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "            # 헤더를 먼저 작성합니다.\n",
        "            writer.writeheader()\n",
        "\n",
        "            # 데이터 행들을 작성합니다.\n",
        "            writer.writerows(data)\n",
        "\n",
        "        print(f\"\\n데이터가 '{filename}' 파일에 성공적으로 저장되었습니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCSV 저장 중 오류가 발생했습니다: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"--- 숭실대학교 공지사항 크롤링 시작 (2025년 이후 필터링) ---\")\n",
        "\n",
        "    # 크롤링 함수를 실행하여 데이터를 가져옵니다.\n",
        "    results = fetch_notices(BASE_URL)\n",
        "\n",
        "    if results:\n",
        "        print(f\"총 {len(results)}개의 (2025년 이후) 공지사항을 찾았습니다.\")\n",
        "\n",
        "        # 크롤링 결과 출력 (처음 5개 항목만 출력)\n",
        "        for i, notice in enumerate(results[:5]):\n",
        "            print(f\"--- 항목 {i+1} ---\")\n",
        "            print(f\"작성일: {notice['작성일']}\")\n",
        "            print(f\"진행상황: {notice['진행상황']}\")\n",
        "            print(f\"카테고리: {notice['카테고리']}\")\n",
        "            print(f\"제목: {notice['제목']}\")\n",
        "            print(f\"등록부서: {notice['등록부서']}\") # <-- 출력 추가\n",
        "            print(f\"조회수: {notice['조회수']}\")   # <-- 출력 추가\n",
        "            print(f\"링크: {notice['링크']}\\n\")\n",
        "\n",
        "        if len(results) > 5:\n",
        "            print(f\"...\")\n",
        "\n",
        "        # CSV 파일로 저장\n",
        "        save_to_csv(results)\n",
        "\n",
        "    else:\n",
        "        print(\"공지사항을 찾지 못했거나 크롤링에 실패했습니다. URL과 CSS Selector를 다시 확인해 주세요.\")\n",
        "\n",
        "    print(\"--- 크롤링 및 CSV 저장 완료 ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNpvl2_rZVRG",
        "outputId": "f7fa71b5-1e66-4da5-dfc7-19d310785682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 숭실대학교 공지사항 크롤링 시작 (2025년 이후 필터링) ---\n",
            "총 15개의 (2025년 이후) 공지사항을 찾았습니다.\n",
            "--- 항목 1 ---\n",
            "작성일: 2025.10.31\n",
            "진행상황: 진행\n",
            "카테고리: 비교과·행사\n",
            "제목: 차세대반도체학과 반도체 전문가 초청 특강 I AI를 통한 반도체 설계 자동화 I 2025.11.6.(목) I 케이던스 강신모 부사장\n",
            "등록부서: 혁신융합대학사업단\n",
            "조회수: 139\n",
            "링크: https://scatch.ssu.ac.kr/%ea%b3%b5%ec%a7%80%ec%82%ac%ed%95%ad/?f&category&paged=1&slug=%EC%B0%A8%EC%84%B8%EB%8C%80%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%99%EA%B3%BC-%EB%B0%98%EB%8F%84%EC%B2%B4-%EC%A0%84%EB%AC%B8%EA%B0%80-%EC%B4%88%EC%B2%AD-%ED%8A%B9%EA%B0%95-i-ai%EB%A5%BC-%ED%86%B5%ED%95%9C&keyword\n",
            "\n",
            "--- 항목 2 ---\n",
            "작성일: 2025.10.31\n",
            "진행상황: 진행\n",
            "카테고리: 장학\n",
            "제목: 한국고등교육재단 인재림 제5기 장학생 선발 안내\n",
            "등록부서: 장학팀\n",
            "조회수: 231\n",
            "링크: https://scatch.ssu.ac.kr/%ea%b3%b5%ec%a7%80%ec%82%ac%ed%95%ad/?f&category&paged=1&slug=%ED%95%9C%EA%B5%AD%EA%B3%A0%EB%93%B1%EA%B5%90%EC%9C%A1%EC%9E%AC%EB%8B%A8-%EC%9D%B8%EC%9E%AC%EB%A6%BC-%EC%A0%9C5%EA%B8%B0-%EC%9E%A5%ED%95%99%EC%83%9D-%EC%84%A0%EB%B0%9C-%EC%95%88%EB%82%B4&keyword\n",
            "\n",
            "--- 항목 3 ---\n",
            "작성일: 2025.10.31\n",
            "진행상황: 진행\n",
            "카테고리: 장학\n",
            "제목: ★ (재공지) 2026학년도 한국지도자육성장학재단 신규 장학생 선발 공고\n",
            "등록부서: 장학팀\n",
            "조회수: 229\n",
            "링크: https://scatch.ssu.ac.kr/%ea%b3%b5%ec%a7%80%ec%82%ac%ed%95%ad/?f&category&paged=1&slug=%E2%98%85-2026%ED%95%99%EB%85%84%EB%8F%84-%ED%95%9C%EA%B5%AD%EC%A7%80%EB%8F%84%EC%9E%90%EC%9C%A1%EC%84%B1%EC%9E%A5%ED%95%99%EC%9E%AC%EB%8B%A8-%EC%8B%A0%EA%B7%9C-%EC%9E%A5%ED%95%99%EC%83%9D-%EC%84%A0&keyword\n",
            "\n",
            "--- 항목 4 ---\n",
            "작성일: 2025.10.30\n",
            "진행상황: 진행\n",
            "카테고리: 봉사\n",
            "제목: 2025 김장나눔 페스티벌 봉사자 모집 안내  [11월 27일]\n",
            "등록부서: 사회공헌팀\n",
            "조회수: 238\n",
            "링크: https://scatch.ssu.ac.kr/%ea%b3%b5%ec%a7%80%ec%82%ac%ed%95%ad/?f&category&paged=1&slug=2025-%EA%B9%80%EC%9E%A5%EB%82%98%EB%88%94-%ED%8E%98%EC%8A%A4%ED%8B%B0%EB%B2%8C-%EB%B4%89%EC%82%AC%EC%9E%90-%EB%AA%A8%EC%A7%91-%EC%95%88%EB%82%B4-11%EC%9B%94-27%EC%9D%BC&keyword\n",
            "\n",
            "--- 항목 5 ---\n",
            "작성일: 2025.10.30\n",
            "진행상황: 진행\n",
            "카테고리: 국제교류\n",
            "제목: 2026년 세종학당 문화인턴 파견 사업 설명회 개최 안내\n",
            "등록부서: 국제팀\n",
            "조회수: 269\n",
            "링크: https://scatch.ssu.ac.kr/%ea%b3%b5%ec%a7%80%ec%82%ac%ed%95%ad/?f&category&paged=1&slug=2026%EB%85%84-%EC%84%B8%EC%A2%85%ED%95%99%EB%8B%B9-%EB%AC%B8%ED%99%94%EC%9D%B8%ED%84%B4-%ED%8C%8C%EA%B2%AC-%EC%82%AC%EC%97%85-%EC%84%A4%EB%AA%85%ED%9A%8C-%EA%B0%9C%EC%B5%9C-%EC%95%88%EB%82%B4&keyword\n",
            "\n",
            "...\n",
            "\n",
            "데이터가 'ssu_notices_2025_onwards.csv' 파일에 성공적으로 저장되었습니다.\n",
            "--- 크롤링 및 CSV 저장 완료 ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}