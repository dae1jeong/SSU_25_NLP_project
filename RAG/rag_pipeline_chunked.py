from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict, Optional, Callable
import sqlite3
import os
from datetime import datetime
import json
import re  # ì •ê·œì‹

import collections
import collections.abc
# bs4ê°€ Python 3.12ì—ì„œ collections.Callableì„ ì°¸ì¡°í•´ì„œ ë‚˜ëŠ” ì˜¤ë¥˜ ë°©ì§€ìš© íŒ¨ì¹˜
if not hasattr(collections, "Callable"):
    collections.Callable = collections.abc.Callable  # type: ignore[attr-defined]

import numpy as np
from rank_bm25 import BM25Okapi
from openai import OpenAI
from dotenv import load_dotenv

import requests
from bs4 import BeautifulSoup

# ------------------------------------------------------------
# í™˜ê²½ ë³€ìˆ˜ (í† í¬ë‚˜ì´ì € ê²½ê³  ì¤„ì´ê¸°ìš©, ì„ íƒ)
# ------------------------------------------------------------
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
os.environ.setdefault("OMP_NUM_THREADS", "1")

# ------------------------------------------------------------------
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ / DB / HF ìºì‹œ / .env ì„¤ì •
# ------------------------------------------------------------------
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(ROOT_DIR, "bm25_tokens.db")

HF_CACHE_DIR = os.path.join(ROOT_DIR, "hf_cache")
os.makedirs(HF_CACHE_DIR, exist_ok=True)

os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR
os.environ["SENTENCE_TRANSFORMERS_HOME"] = HF_CACHE_DIR

print("[RAG] Using DB_PATH =", DB_PATH)
print("[RAG] Using HF cache dir =", HF_CACHE_DIR)

env_path = os.path.join(ROOT_DIR, ".env")
print(f"[RAG] Loading .env from: {env_path}")

if os.path.exists(env_path):
    load_dotenv(env_path)
    print("[RAG] .env íŒŒì¼ ë¡œë“œ ì„±ê³µ")
else:
    print("[RAG] ğŸš¨ ê²½ê³ : .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

# ==========================================================
# 0. í•™ì‹ ê´€ë ¨ ìŠ¤í¬ë˜í•‘ ìœ í‹¸ (soongguri / ê¸°ìˆ™ì‚¬ ì‹ë‹¹)
# ==========================================================

SOONGGURI_URL = "https://soongguri.com/m/"
DORM_FOOD_URL = (
    "https://ssudorm.ssu.ac.kr:444/"
    "SShostel/mall_main.php?viewform=B0001_foodboard_list&board_no=1"
)

# soongguriê°€ ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ë¼ê³  ë¯¿ë„ë¡ í—¤ë” ì„¸íŒ…
SOONGGURI_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
}


def _clean_line(text: str) -> str:
    """ê³µë°± ì •ë¦¬ + ì“¸ëª¨ì—†ëŠ” ê¸°í˜¸ ì œê±°ìš© ìœ í‹¸."""
    if not text:
        return ""
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def _normalize_sdt(date_str: str | None) -> tuple[str, str]:
    """
    date_str:
      - None        â†’ ì˜¤ëŠ˜ ë‚ ì§œ
      - '20251125'  â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
      - '2025-11-25' â†’ '-' ì œê±° í›„ ì‚¬ìš©
    return: (sdt, pretty_label)
    """
    if not date_str:
        dt = datetime.now()
        sdt = dt.strftime("%Y%m%d")
        label = dt.strftime("%Y-%m-%d")
        return sdt, label

    ds = date_str.strip()

    # 2025-11-25 í˜•ì‹
    if len(ds) == 10 and ds[4] == "-" and ds[7] == "-":
        try:
            dt = datetime.strptime(ds, "%Y-%m-%d")
            return dt.strftime("%Y%m%d"), dt.strftime("%Y-%m-%d")
        except ValueError:
            pass

    # 20251125 í˜•ì‹
    if len(ds) == 8 and ds.isdigit():
        try:
            dt = datetime.strptime(ds, "%Y%m%d")
            return ds, dt.strftime("%Y-%m-%d")
        except ValueError:
            pass

    # ì´ìƒí•˜ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ fallback
    dt = datetime.now()
    return dt.strftime("%Y%m%d"), dt.strftime("%Y-%m-%d")


def fetch_soongguri_menu(date_str: str | None = None, rcd: str = "1") -> str:
    """
    soongguri AJAX ì—”ë“œí¬ì¸íŠ¸(/m/m_req/m_menu.php)ì—ì„œ
    ì£¼ì–´ì§„ ë‚ ì§œ(date_str)ì™€ ì‹ë‹¹ ì½”ë“œ(rcd)ì˜ ë©”ë‰´ HTMLì„ ì§ì ‘ ê°€ì ¸ì™€ì„œ íŒŒì‹±.

    date_str:
      - None â†’ ì˜¤ëŠ˜
      - '2025-11-25' ë˜ëŠ” '20251125' ë‘˜ ë‹¤ í—ˆìš©
    rcd:
      - "1": í•™ìƒì‹ë‹¹
      - "2": ìˆ­ì‹¤ë„ë‹´ì‹ë‹¹
      - "4": ìŠ¤ë‚µì½”ë„ˆ
      - "5": í‘¸ë“œì½”íŠ¸
      - "6": THE KITCHEN
      - "7": Faculty Lounge
    """
    sdt, label = _normalize_sdt(date_str)

    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    try:
        session = requests.Session()
        session.headers.update(SOONGGURI_HEADERS)

        # ì‹¤ì œ AJAX ë©”ë‰´ ë°ì´í„° ìš”ì²­ (m_menu.php)
        params = {"rcd": rcd, "sdt": sdt}
        resp = session.get(
            SOONGGURI_URL + "m_req/m_menu.php",
            params=params,
            timeout=10,
            verify=False,
        )
    except Exception as e:
        return (
            "[ìƒí˜‘ ì‹ë‹¹ ë©”ë‰´]\n"
            "soongguri ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì§€ ëª»í–ˆì–´ìš”.\n"
            f"(ì—ëŸ¬: {e})\n"
            "â†’ ì§ì ‘ í™•ì¸: https://soongguri.com/m/"
        )

    if resp.status_code != 200 or len(resp.text.strip()) < 50:
        return (
            f"[ìƒí˜‘ ì‹ë‹¹ ë©”ë‰´ - {label}]\n"
            "í˜„ì¬ soongguriì—ì„œ í•™ì‹ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”.\n"
            "â†’ ì§ì ‘ í™•ì¸: https://soongguri.com/m/"
        )

    soup = BeautifulSoup(resp.text, "html.parser")
    table = soup.find("table")

    if not table:
        return (
            f"[ìƒí˜‘ ì‹ë‹¹ ë©”ë‰´ - {label}]\n"
            "ì‹ë‹¨ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.\n"
            "â†’ ì§ì ‘ í™•ì¸: https://soongguri.com/m/"
        )

    menus: list[str] = []

    for tr in table.find_all("tr"):
        name_td = tr.find("td", class_="menu_nm")
        list_td = tr.find("td", class_="menu_list")
        if not (name_td and list_td):
            continue

        meal_name = name_td.get_text(strip=True)  # ì˜ˆ: ì¤‘ì‹1, ì„ì‹1...

        # ì½”ë„ˆëª… [ëšë°°ê¸°ì½”ë„ˆ] ë“±
        corner = ""
        for tag in list_td.find_all(["font", "b", "span"]):
            txt = tag.get_text(strip=True)
            m = re.search(r"\[[^\]]+\]", txt)
            if m:
                corner = m.group(0)
                break

        # ë©”ì¸ ë©”ë‰´ (â˜… í‘œì‹œ)
        main_dish = ""
        for tag in list_td.find_all(["font", "b", "span"]):
            txt = tag.get_text(" ", strip=True)
            if "â˜…" in txt:
                main_dish = txt.replace("â˜…", "").strip()
                break

        # ë°˜ì°¬ í›„ë³´ë“¤
        side_dishes: list[str] = []
        for li in list_td.select("ul.mean_list li, ul.mean_list td, ul.mean_list .xl65"):
            t = _clean_line(li.get_text(strip=True))
            if not t:
                continue
            if "ì•ŒëŸ¬ì§€ìœ ë°œì‹í’ˆ" in t or "ì›ì‚°ì§€" in t:
                continue
            if all(ord(ch) < 128 for ch in t):  # ì „ë¶€ ASCII(ì˜ë¬¸)ë©´ ìŠ¤í‚µ
                continue
            if t not in side_dishes:
                side_dishes.append(t)

        line = meal_name
        if corner:
            line += f" {corner}"
        if main_dish:
            line += f" - {main_dish}"
        if side_dishes:
            line += "\n  Â· " + "\n  Â· ".join(side_dishes)

        menus.append(line)

    if not menus:
        return (
            f"[ìƒí˜‘ ì‹ë‹¹ ë©”ë‰´ - {label}]\n"
            "ë©”ë‰´ íŒŒì‹± ì‹¤íŒ¨ (í•­ëª© ì—†ìŒ)\n"
            "â†’ https://soongguri.com/m/ ì—ì„œ ì§ì ‘ í™•ì¸í•´ ì£¼ì„¸ìš”."
        )

    return f"[ìƒí˜‘ ì‹ë‹¹ ë©”ë‰´ - {label}]\n" + "\n\n".join(menus)


def fetch_dorm_menu() -> str:
    """
    ìˆ­ì‹¤ëŒ€ ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì£¼ê°„ ì‹ë‹¨í‘œ(boxstyle02 í…Œì´ë¸”)ì—ì„œ 'ì˜¤ëŠ˜ ë‚ ì§œ'ì— í•´ë‹¹í•˜ëŠ”
    ì¡°ì‹/ì¤‘ì‹/ì„ì‹ ë©”ë‰´ë¥¼ íŒŒì‹±í•œë‹¤.
    """
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    try:
        resp = requests.get(DORM_FOOD_URL, timeout=10, verify=False)
        resp.raise_for_status()
    except Exception as e:
        return f"[í•™ì‹] ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(resp.text, "html.parser")

    table = soup.find("table", class_="boxstyle02")
    if not table:
        return "[í•™ì‹] ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´ í…Œì´ë¸”(boxstyle02)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    today = datetime.now().strftime("%Y-%m-%d")
    target_row = None

    # ì²« ë²ˆì§¸ trëŠ” í—¤ë”, ê·¸ ë‹¤ìŒë¶€í„° ì‹¤ì œ ë‚ ì§œ í–‰
    for tr in table.find_all("tr")[1:]:
        th = tr.find("th")
        if not th:
            continue
        text = th.get_text(strip=True)  # ì˜ˆ: "2025-11-21 (ê¸ˆ)"
        if today in text:
            target_row = tr
            break

    # ì˜¤ëŠ˜ ë‚ ì§œê°€ ì—†ìœ¼ë©´, ì£¼ê°„ ë©”ë‰´ ìš”ì•½ ë°˜í™˜
    if target_row is None:
        rows_text: list[str] = []
        for tr in table.find_all("tr")[1:]:
            th = tr.find("th")
            if not th:
                continue
            date_text = th.get_text(strip=True)
            tds = tr.find_all("td")
            if len(tds) < 3:
                continue
            breakfast = tds[0].get_text("\n", strip=True)
            lunch = tds[1].get_text("\n", strip=True)
            dinner = tds[2].get_text("\n", strip=True)
            row_str = (
                f"{date_text}\n"
                f"  Â· ì¡°ì‹: {breakfast}\n"
                f"  Â· ì¤‘ì‹: {lunch}\n"
                f"  Â· ì„ì‹: {dinner}"
            )
            rows_text.append(row_str)

        if not rows_text:
            return "[í•™ì‹] ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì£¼ê°„ ë©”ë‰´ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return "[ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì£¼ê°„ ë©”ë‰´]\n\n" + "\n\n".join(rows_text)

    # ì˜¤ëŠ˜ ë‚ ì§œ í–‰ì„ ì°¾ì€ ê²½ìš°
    tds = target_row.find_all("td")
    breakfast = tds[0].get_text("\n", strip=True) if len(tds) >= 1 else ""
    lunch = tds[1].get_text("\n", strip=True) if len(tds) >= 2 else ""
    dinner = tds[2].get_text("\n", strip=True) if len(tds) >= 3 else ""
    both = tds[3].get_text("\n", strip=True) if len(tds) >= 4 else ""

    date_label = target_row.find("th").get_text(strip=True)

    lines = [
        f"[ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´ - {date_label}]",
        f"Â· ì¡°ì‹: {breakfast or 'ë¯¸ìš´ì˜'}",
        f"Â· ì¤‘ì‹: {lunch or 'ë¯¸ë“±ë¡'}",
        f"Â· ì„ì‹: {dinner or 'ë¯¸ë“±ë¡'}",
    ]
    if both:
        lines.append(f"Â· ì¤‘Â·ì„ì‹: {both}")

    return "\n".join(lines)


def build_meal_context() -> str:
    """
    soongguri(ìƒí˜‘) + ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨.
    intent == "í•™ì‹_ê²€ìƒ‰"ì¼ ë•Œ ì´ ë¬¸ìì—´ì„ LLMì— ë„˜ê¸´ë‹¤.
    """
    soongguri_text = fetch_soongguri_menu()
    dorm_text = fetch_dorm_menu()

    context_parts = [
        "ë‹¤ìŒì€ ìˆ­ì‹¤ëŒ€í•™êµ ì˜¤ëŠ˜ì˜ í•™ì‹ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤.",
        "",
        soongguri_text,
        "",
        dorm_text,
    ]
    return "\n".join(context_parts)


# ==============================================
# 1. BM25 / RAG íŒŒíŠ¸
# ==============================================

@dataclass
class ChunkDocument:
    id: str
    text: str
    meta: Dict
    tokens: List[str]


def load_chunks_from_db(db_path: str = DB_PATH) -> List[ChunkDocument]:
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    cur.execute("SELECT id, text, metadata, tokens FROM chunks")
    rows = cur.fetchall()
    conn.close()

    docs: List[ChunkDocument] = []
    for id_, text, metadata_json, tokens_str in rows:
        meta = json.loads(metadata_json)
        tokens = tokens_str.split()
        docs.append(ChunkDocument(id=id_, text=text, meta=meta, tokens=tokens))
    print(f"[DB] ì´ {len(docs)}ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
    return docs


class BM25DBRetriever:
    def __init__(self, chunk_docs: List[ChunkDocument]):
        self.docs = chunk_docs
        self.corpus_tokens = [d.tokens for d in chunk_docs]  # DBì— ìˆëŠ” í† í° ì‚¬ìš©
        self.bm25 = BM25Okapi(self.corpus_tokens)
        print(f"[BM25] DB í† í°ìœ¼ë¡œ BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    def search(self, query: str, top_k: int = 30) -> List[ChunkDocument]:
        query_tokens = query.strip().split()
        scores = self.bm25.get_scores(query_tokens)
        ranked_indices = np.argsort(-scores)[:top_k]
        return [self.docs[i] for i in ranked_indices]


class VectorReranker:
    """
    âš ï¸ ì„¸ê·¸í´íŠ¸ ë°©ì§€ë¥¼ ìœ„í•´ sentence_transformers ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ 
    BM25 ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ìƒìœ„ top_kë§Œ ì˜ë¼ì„œ ë°˜í™˜í•˜ëŠ” ë‹¨ìˆœí•œ reranker.
    """

    def __init__(self, model_name: str = "jhgan/ko-sroberta-multitask"):
        print("[VectorReranker] sentence_transformers ë¹„í™œì„±í™”ë¨ â†’ BM25 ìˆœì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        self.model = None  # ì‹¤ì œ ëª¨ë¸ ë¡œë”© ì•ˆ í•¨

    def rerank(self, query: str, candidates: List[ChunkDocument], top_k: int = 5) -> List[ChunkDocument]:
        return candidates[:top_k]


class RAGPipeline:
    def __init__(self, bm25_top_k: int = 30, rerank_top_k: int = 5):
        self.chunk_docs = load_chunks_from_db()
        self.bm25 = BM25DBRetriever(self.chunk_docs)
        self.reranker = VectorReranker()
        self.bm25_top_k = bm25_top_k
        self.rerank_top_k = rerank_top_k

    def retrieve(self, query: str, intent: str = None, slots: Dict = None):
        slots = slots or {}
        candidates = self.bm25.search(query, top_k=self.bm25_top_k)

        # intent / slots í•„í„°
        if intent:
            candidates = [
                d for d in candidates
                if (intent == "ê°•ì˜í‰_ê²€ìƒ‰" and d.meta.get("source") == "lecture_review")
                or (intent == "ê³µì§€_ê²€ìƒ‰" and d.meta.get("source") == "notice")
                or (intent == "ë™ì•„ë¦¬_ê²€ìƒ‰" and d.meta.get("source") == "club")
            ]

        prof = slots.get("professor_name") or slots.get("professor")
        if prof:
            candidates = [
                d for d in candidates
                if "professor" in d.meta and prof in d.meta["professor"]
            ]

        dept = slots.get("department")
        if dept:
            candidates = [
                d for d in candidates
                if "department" in d.meta and dept in d.meta["department"]
            ]

        club_name = slots.get("club_name")
        if club_name:
            candidates = [
                d for d in candidates
                if "club_name" in d.meta and club_name in d.meta["club_name"]
            ]

        if not candidates:
            candidates = self.bm25.search(query, top_k=self.bm25_top_k)

        return self.reranker.rerank(query, candidates, top_k=self.rerank_top_k)

    def build_prompt(self, query: str, docs: List[ChunkDocument]) -> tuple[str, str]:
        context_blocks = []
        for i, d in enumerate(docs, start=1):
            header = f"[ë¬¸ì„œ {i} | {d.meta.get('source', 'unknown')} | id={d.id}]"
            block = f"{header}\n{d.text}"
            context_blocks.append(block)
        context_text = "\n\n---\n\n".join(context_blocks)
        system_msg = (
            "ë„ˆëŠ” ìˆ­ì‹¤ëŒ€í•™êµ ê´€ë ¨ ì •ë³´ë§Œ ë‹µë³€í•˜ëŠ” ì±—ë´‡ì´ì•¼.\n"
            "ì•„ë˜ì— ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ì•„ì„œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.\n"
            "ëª¨ë¥´ê² ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´."
        )
        user_msg = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{query}\n\n"
            f"ë‹¤ìŒì€ ê´€ë ¨ ë¬¸ì„œë“¤ì´ì•¼. ì´ ì •ë³´ë§Œ ê·¼ê±°ë¡œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.\n\n"
            f"{context_text}"
        )
        return system_msg, user_msg

    def answer_with_llm(
        self,
        query: str,
        llm_call: Callable[[str, str], str],
        intent: str = None,
        slots: Dict = None,
    ) -> str:
        """
        ì§ˆë¬¸/ì˜ë„ì— ë”°ë¼ í•™ì‹ ìŠ¤í¬ë˜í•‘ ë˜ëŠ” ì¼ë°˜ RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±.
        """

        # âœ… 1) ì§ˆë¬¸ ë¬¸ìì—´ë§Œ ë³´ê³  'í•™ì‹' ê´€ë ¨ ì˜ë„ ìë™ íŒë³„
        q_lower = query.lower()
        if (
            ("í•™ì‹" in query)
            or ("ë©”ë‰´" in query)
            or ("ë°¥ ë­" in query)
            or ("ë°¥ ë­ ë‚˜ì™€" in query)
            or ("ì˜¤ëŠ˜ ë°¥" in query)
            or ("ìƒí˜‘" in query)
            or ("ê¸°ìˆ™ì‚¬ ì‹ë‹¹" in query)
        ):
            intent = "í•™ì‹_ê²€ìƒ‰"

        # âœ… 2) í•™ì‹ ì˜ë„ë©´ RAG ë§ê³  ì‹¤ì‹œê°„ ìŠ¤í¬ë˜í•‘ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
        if intent == "í•™ì‹_ê²€ìƒ‰":
            meal_context = build_meal_context()
            system_msg = (
                "ë„ˆëŠ” ìˆ­ì‹¤ëŒ€í•™êµ í•™ì‹ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” ì±—ë´‡ì´ì•¼.\n"
                "ì•„ë˜ ì»¨í…ìŠ¤íŠ¸(ìƒí˜‘/ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´)ë¥¼ ì°¸ê³ í•´ì„œ, "
                "ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ ì˜¤ëŠ˜ì˜ í•™ì‹ ì •ë³´ë¥¼ ê°„ëµí•˜ê³  ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ì„œ ì•Œë ¤ì¤˜.\n"
                "ë©”ë‰´ ì´ë¦„, ì½”ë„ˆ ì´ë¦„, ê°€ê²©, ë¼ë‹ˆ(ì¡°ì‹/ì¤‘ì‹/ì„ì‹) ë“±ì„ ì •ëˆí•´ì„œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´."
            )
            user_msg = (
                f"ì‚¬ìš©ì ì§ˆë¬¸: {query}\n\n"
                f"ë‹¤ìŒì€ ì˜¤ëŠ˜ì˜ í•™ì‹ ì •ë³´ì•¼:\n\n{meal_context}"
            )
            return llm_call(system_msg, user_msg)

        # âœ… 3) ê·¸ ì™¸ëŠ” ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
        docs = self.retrieve(query, intent=intent, slots=slots or {})
        system_msg, user_msg = self.build_prompt(query, docs)
        return llm_call(system_msg, user_msg)


# =========================
# 6. GPT API í˜¸ì¶œ í•¨ìˆ˜
# =========================

def call_openai_api(system_msg: str, user_msg: str) -> str:
    """
    OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    .env íŒŒì¼ì—ì„œ í‚¤ë¥¼ ë¡œë“œí•˜ë¯€ë¡œ ë³´ì•ˆìƒ ì•ˆì „í•©ë‹ˆë‹¤.
    """
    api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        return "[ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.0,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"[LLM í˜¸ì¶œ ì˜¤ë¥˜] API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# =========================
# 7. ì „ì—­ RAG ì¸ìŠ¤í„´ìŠ¤ (ì›¹ ì„œë²„ì—ì„œ ë°”ë¡œ ì‚¬ìš©)
# =========================

print("[RAG] RAGPipeline ì´ˆê¸°í™” ì¤‘...")
rag = RAGPipeline()
print("[RAG] RAGPipeline ì´ˆê¸°í™” ì™„ë£Œ!")


# =========================
# 8. ê°„ë‹¨ CLI í…ŒìŠ¤íŠ¸ìš© main
# =========================

if __name__ == "__main__":
    print(f"[RAG] Using DB_PATH = {DB_PATH}")
    print("í„°ë¯¸ë„ì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. 'í•™ì‹'ì´ë¼ê³  ì³ë³´ì„¸ìš”.\n")

    while True:
        try:
            q = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: ì—”í„°ë§Œ ì…ë ¥): ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if not q:
            break

        print("\n--- ğŸ§  LLMì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ---")

        # ì—¬ê¸°ì„œ intentëŠ” êµ³ì´ ì•ˆ ì¤˜ë„ ë˜ì§€ë§Œ, ë„£ì–´ë„ ìƒê´€ ì—†ìŒ
        lower_q = q.lower()
        if ("í•™ì‹" in q) or ("ë©”ë‰´" in q) or ("ë°¥ ë­" in q):
            intent = "í•™ì‹_ê²€ìƒ‰"
        else:
            intent = None

        answer = rag.answer_with_llm(q, llm_call=call_openai_api, intent=intent)

        print("\n=======================================================")
        print(f"[ê¶ê¸ˆí–ˆìŠˆ(SSU) ë‹µë³€]\n{answer}")
        print("=======================================================\n")