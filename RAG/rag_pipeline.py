"""
RAG íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ (SSU_25_NLP_PROJECTìš© ìˆ˜ì •ë³¸)

ì—­í• :
    - í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ ssu_chatbot_data.db ì—ì„œ ê³µì§€/ê°•ì˜í‰/ë™ì•„ë¦¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ Documentë¡œ ë³€í™˜
    - BM25ë¡œ 1ì°¨ ê²€ìƒ‰, sentence-transformersë¡œ 2ì°¨ ë²¡í„° re-rank
    - LLMì— ì¤„ ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±

ì£¼ì˜:
    - ì´ íŒŒì¼ì€ RAG í´ë” ì•ˆì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤: SSU_25_NLP_PROJECT/RAG/rag_pipeline.py
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict, Optional, Callable
import sqlite3
import math
import os
import sys
import unicodedata  # Mac ì˜¤ë¥˜ í•´ê²°ìš©

import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
from kiwipiepy import Kiwi
from openai import OpenAI
from dotenv import load_dotenv

# ------------------------------------------------------------------
# !! ì—¬ê¸° ì¤‘ìš” !!
# RAG í´ë” ê¸°ì¤€ìœ¼ë¡œ í•œ ì¹¸ ì˜¬ë¼ê°€ì„œ ë£¨íŠ¸ì˜ DBë¥¼ ë°”ë¼ë³´ê²Œ í•¨
# ------------------------------------------------------------------
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(ROOT_DIR, "ssu_chatbot_data.db")

HF_CACHE_DIR = os.path.join(ROOT_DIR, "hf_cache")
os.makedirs(HF_CACHE_DIR, exist_ok=True)

os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR
os.environ["SENTENCE_TRANSFORMERS_HOME"] = HF_CACHE_DIR

print("[RAG] Using DB_PATH =", DB_PATH)
print("[RAG] Using HF cache dir =", HF_CACHE_DIR)

# .env íŒŒì¼ ë¡œë“œ (API í‚¤ ë³´ì•ˆ)
env_path = os.path.join(ROOT_DIR, ".env")
print(f"[RAG] Loading .env from: {env_path}") # ê²½ë¡œ í™•ì¸ìš© ë¡œê·¸

if os.path.exists(env_path):
    load_dotenv(env_path)
    print("[RAG] .env íŒŒì¼ ë¡œë“œ ì„±ê³µ")
else:
    print("[RAG] ğŸš¨ ê²½ê³ : .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

# =========================
# 1. Document ìŠ¤í‚¤ë§ˆ ì •ì˜
# =========================

@dataclass
class Document:
    id: str               # "notice:123", "review:45" ê°™ì€ ë‚´ë¶€ ID
    type: str             # "notice" | "review" | "club"
    text: str             # ê²€ìƒ‰ê³¼ LLM ì»¨í…ìŠ¤íŠ¸ì— ì‚¬ìš©í•  ë³¸ë¬¸
    meta: Dict[str, str]  # ë¶€ê°€ ì •ë³´ (í•™ê³¼, êµìˆ˜ëª…, ë‚ ì§œ, ë™ì•„ë¦¬ ì´ë¦„ ë“±)


# =========================
# 2. DB â†’ Document ë¡œë”
# =========================

def load_notices() -> List[Document]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    cur.execute("""
        SELECT id, title, category, post_date, status, full_body_text, link, department
        FROM notices
    """)
    rows = cur.fetchall()
    conn.close()

    docs: List[Document] = []
    for id_, title, category, post_date, status, body, link, dept in rows:
        title = title or ""
        category = category or ""
        post_date = post_date or ""
        status = status or ""
        body = body or ""
        dept = dept or "ì •ë³´ ì—†ìŒ"
        link = link or ""

        text = (
            f"[ê³µì§€] {title}\n"
            f"- ì¹´í…Œê³ ë¦¬: {category}\n"
            f"- í•™ê³¼: {dept}\n"
            f"- ê²Œì‹œì¼: {post_date}\n"
            f"- ìƒíƒœ: {status}\n\n"
            f"{body}"
        )
        meta = {
            "title": title,
            "category": category,
            "post_date": post_date,
            "status": status,
            "department": dept,
            "link": link,
        }
        docs.append(
            Document(
                id=f"notice:{id_}",
                type="notice",
                text=text,
                meta=meta,
            )
        )
    return docs


def load_reviews() -> List[Document]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    cur.execute("""
        SELECT id, subject_name, professor_name, star_rating, semester, review_text
        FROM lecture_reviews
    """)
    rows = cur.fetchall()
    conn.close()

    docs: List[Document] = []
    for id_, subj, prof, star, sem, review_text in rows:
        subj = subj or ""
        prof = prof or "ì •ë³´ ì—†ìŒ"
        sem = sem or ""
        review_text = review_text or ""
        star = star if star is not None else 0.0

        text = (
            f"[ê°•ì˜í‰] {subj} - {prof} êµìˆ˜ë‹˜\n"
            f"- ë³„ì : {star}\n"
            f"- ìˆ˜ê°• í•™ê¸°: {sem}\n\n"
            f"{review_text}"
        )
        meta = {
            "subject_name": subj,
            "professor_name": prof,
            "star_rating": str(star),
            "semester": sem,
        }
        docs.append(
            Document(
                id=f"review:{id_}",
                type="review",
                text=text,
                meta=meta,
            )
        )
    return docs


def load_clubs() -> List[Document]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    cur.execute("""
        SELECT id, club_name, category, description, recruitment_info, source_url
        FROM clubs
    """)
    rows = cur.fetchall()
    conn.close()

    docs: List[Document] = []
    for id_, name, category, desc, recruit, url in rows:
        name = name or "ì œëª© ì—†ìŒ"
        category = category or "ë™ì•„ë¦¬"
        desc = desc or ""
        recruit = recruit or ""
        url = url or ""

        text = (
            f"[ë™ì•„ë¦¬] {name} (ë¶„ë¥˜: {category})\n"
            f"- ëª¨ì§‘ ì •ë³´: {recruit}\n"
            f"- ë§í¬: {url}\n\n"
            f"{desc}"
        )
        meta = {
            "club_name": name,
            "category": category,
            "recruitment_info": recruit,
            "source_url": url,
        }
        docs.append(
            Document(
                id=f"club:{id_}",
                type="club",
                text=text,
                meta=meta,
            )
        )
    return docs


def load_all_docs() -> List[Document]:
    notices = load_notices()
    reviews = load_reviews()
    clubs = load_clubs()
    print(
        f"[RAG] loaded notices={len(notices)}, "
        f"reviews={len(reviews)}, clubs={len(clubs)}"
    )
    return notices + reviews + clubs


# =========================
# 3. BM25 1ì°¨ ê²€ìƒ‰ê¸°
# =========================

try:
    KIWI_PROCESSOR = Kiwi()
except Exception as e:
    print(f"[ERROR] Kiwi ê°ì²´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    KIWI_PROCESSOR = None 

def simple_tokenize(text: str) -> List[str]:
    """
    Kiwipiepy í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ì— íŠ¹í™”ëœ í† í¬ë‚˜ì´ì§•.
    **UnicodeDecodeError ë°©ì§€ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬ ì¶”ê°€.**
    """
    if not KIWI_PROCESSOR:
        return str(text or "").strip().split()

    # ğŸŒŸğŸŒŸğŸŒŸ 1. ë°©ì–´ ì½”ë“œ: ì…ë ¥ê°’ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ ğŸŒŸğŸŒŸğŸŒŸ
    if not text:
        return []
    
    text = str(text).strip()

    # ğŸŒŸğŸŒŸğŸŒŸ 2. Mac í˜¸í™˜ì„±: ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (ì´ê²Œ ì—†ìœ¼ë©´ ì—ëŸ¬ë‚¨) ğŸŒŸğŸŒŸğŸŒŸ
    text = unicodedata.normalize('NFC', text)
    
    # 3. ìœ ë‹ˆì½”ë“œ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ê°•ì œë¡œ ë¬´ì‹œí•˜ê³  í´ë¦° í…ìŠ¤íŠ¸ ìƒì„±
    try:
        clean_text = text.encode('utf-8', 'ignore').decode('utf-8')
    except Exception:
        clean_text = text

    if not clean_text:
        return []

    tokens: List[str] = []
    
    try:
        for token in KIWI_PROCESSOR.tokenize(clean_text, normalize_coda=True):
            if token.tag.startswith(('N', 'V', 'M', 'SL', 'SN')):
                tokens.append(token.form)
    except Exception as e:
        # í† í°í™” ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ, ë©ˆì¶”ì§€ ì•Šê³  í•´ë‹¹ ë¬¸ì¥ì€ ê±´ë„ˆë›°ê±°ë‚˜ ì–´ì ˆ ë‹¨ìœ„ë¡œ ëŒ€ì²´
        print(f"[Tokenize Warning] Skipped text due to error: {e}")
        return clean_text.split()
            
    return tokens

class BM25Retriever:
    def __init__(self, docs: List[Document]):
        self.docs = docs
        # í† í°í™” ê³¼ì •ì—ì„œ ì§„í–‰ ìƒí™©ì„ ì•Œê¸° ì–´ë ¤ìš°ë‹ˆ ê°„ë‹¨í•œ ë©”ì‹œì§€ ì¶œë ¥
        print(f"[BM25] {len(docs)}ê°œ ë¬¸ì„œ í† í°í™” ì‹œì‘...")
        self.corpus_tokens: List[List[str]] = [simple_tokenize(d.text) for d in docs]
        self.bm25 = BM25Okapi(self.corpus_tokens)
        print(f"[BM25] í† í°í™” ë° ì¸ë±ì‹± ì™„ë£Œ.")

    def search(self, query: str, top_k: int = 30) -> List[Document]:
        tokens = simple_tokenize(query)
        scores = self.bm25.get_scores(tokens)
        ranked_indices = sorted(
            range(len(self.docs)),
            key=lambda i: scores[i],
            reverse=True,
        )[:top_k]
        return [self.docs[i] for i in ranked_indices]


# =========================
# 4. ë²¡í„° ê¸°ë°˜ ì¬ì •ë ¬ê¸°
# =========================

class VectorReranker:
    def __init__(
        self,
        model_name: str = "jhgan/ko-sroberta-multitask",
    ):
        self.model = SentenceTransformer(model_name)

    @staticmethod
    def _cosine_sim(query_emb: np.ndarray, doc_embs: np.ndarray) -> np.ndarray:
        q = query_emb / (np.linalg.norm(query_emb) + 1e-12)
        d = doc_embs / (np.linalg.norm(doc_embs, axis=1, keepdims=True) + 1e-12)
        sims = d @ q
        return sims

    def rerank(self, query: str, candidates: List[Document], top_k: int = 5) -> List[Document]:
        if not candidates:
            return []

        texts = [d.text for d in candidates]
        doc_embs = self.model.encode(texts, convert_to_numpy=True)
        query_emb = self.model.encode([query], convert_to_numpy=True)[0]
        sims = self._cosine_sim(query_emb, doc_embs)

        ranked_indices = np.argsort(-sims)[:top_k]
        return [candidates[i] for i in ranked_indices]


# =========================
# 5. RAG íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
# =========================

class RAGPipeline:
    def __init__(
        self,
        docs: Optional[List[Document]] = None,
        bm25_top_k: int = 30,
        rerank_top_k: int = 5,
    ):
        self.docs = docs or load_all_docs()
        self.bm25 = BM25Retriever(self.docs)
        self.reranker = VectorReranker()
        self.bm25_top_k = bm25_top_k
        self.rerank_top_k = rerank_top_k

    def retrieve(
        self,
        query: str,
        intent: Optional[str] = None,
        slots: Optional[Dict[str, str]] = None,
    ) -> List[Document]:
        slots = slots or {}

        # 1) BM25 í›„ë³´
        candidates = self.bm25.search(query, top_k=self.bm25_top_k)

        # 2) intent/slots ê¸°ë°˜ í•„í„°
        filtered: List[Document] = candidates

        if intent == "ê°•ì˜í‰_ê²€ìƒ‰":
            filtered = [d for d in filtered if d.type == "review"]
        elif intent == "ê³µì§€_ê²€ìƒ‰":
            filtered = [d for d in filtered if d.type == "notice"]
        elif intent == "ë™ì•„ë¦¬_ê²€ìƒ‰":
            filtered = [d for d in filtered if d.type == "club"]

        prof = slots.get("professor_name") or slots.get("professor")
        if prof:
            filtered = [
                d for d in filtered
                if d.meta.get("professor_name") and prof in d.meta.get("professor_name", "")
            ]

        dept = slots.get("department")
        if dept:
            filtered = [
                d for d in filtered
                if d.meta.get("department") and dept in d.meta.get("department", "")
            ]

        club_name = slots.get("club_name")
        if club_name:
            filtered = [
                d for d in filtered
                if d.meta.get("club_name") and club_name in d.meta.get("club_name", "")
            ]

        if not filtered:
            filtered = candidates

        # 3) ë²¡í„° ê¸°ë°˜ ì¬ì •ë ¬
        final_docs = self.reranker.rerank(query, filtered, top_k=self.rerank_top_k)
        return final_docs

    def build_prompt(self, query: str, docs: List[Document]) -> (str, str):
        context_blocks = []
        for i, d in enumerate(docs, start=1):
            header = f"[ë¬¸ì„œ {i} | {d.type} | id={d.id}]"
            block = f"{header}\n{d.text}"
            context_blocks.append(block)

        context_text = "\n\n---\n\n".join(context_blocks)

        system_msg = (
            "ë„ˆëŠ” ìˆ­ì‹¤ëŒ€í•™êµ ê´€ë ¨ ì •ë³´ë§Œ ë‹µë³€í•˜ëŠ” ì±—ë´‡ì´ì•¼.\n"
            "ì•„ë˜ì— ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ì•„ì„œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.\n"
            "ëª¨ë¥´ê² ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´."
        )

        user_msg = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{query}\n\n"
            f"ë‹¤ìŒì€ ê´€ë ¨ ë¬¸ì„œë“¤ì´ì•¼. ì´ ì •ë³´ë§Œ ê·¼ê±°ë¡œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.\n\n"
            f"{context_text}"
        )

        return system_msg, user_msg

    def answer_with_llm(
        self,
        query: str,
        llm_call: Callable[[str, str], str],
        intent: Optional[str] = None,
        slots: Optional[Dict[str, str]] = None,
    ) -> str:
        docs = self.retrieve(query, intent=intent, slots=slots)
        system_msg, user_msg = self.build_prompt(query, docs)
        answer = llm_call(system_msg, user_msg)


        # ğŸŒŸğŸŒŸğŸŒŸ ì„±ëŠ¥í‰ê°€ë¥¼ ìœ„í•œ ë‹µë³€ ìƒì„± ì‹œ RAGAS ì…ë ¥ êµ¬ì¡°ë¡œ ë³€í™˜
        # ragas_input = {
        #     "query": query,
        #     "answer": answer,
        #     "context": [
        #         {"id": d.id, "text": d.text, "meta": d.meta} for d in docs
        #     ]
        # }
        # return ragas_input
        
        return answer


# ğŸŒŸğŸŒŸğŸŒŸ GPT API í˜¸ì¶œ í•¨ìˆ˜ (ìˆ˜ì •ë³¸: ë³´ì•ˆ ì ìš©) ğŸŒŸğŸŒŸğŸŒŸ

def call_openai_api(system_msg: str, user_msg: str) -> str:
    """
    OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    .env íŒŒì¼ì—ì„œ í‚¤ë¥¼ ë¡œë“œí•˜ë¯€ë¡œ ë³´ì•ˆìƒ ì•ˆì „í•©ë‹ˆë‹¤.
    """
    # .envì—ì„œ ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        return "[ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    try:
        # GPT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(api_key=api_key)
        
        # API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini", 
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.0 
        )
        return response.choices[0].message.content
        
    except Exception as e:
        return f"[LLM í˜¸ì¶œ ì˜¤ë¥˜] API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# =========================
# 6. ê°„ë‹¨ í…ŒìŠ¤íŠ¸ìš© main
# =========================

if __name__ == "__main__":
    print(f"[RAG] Using DB_PATH = {DB_PATH}")
    
    rag = RAGPipeline()

    while True:
        try:
            q = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: ì—”í„°ë§Œ ì…ë ¥): ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if not q:
            break

        print("\n--- ğŸ§  LLMì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ---")
        
        # RAG ê²€ìƒ‰ê³¼ GPT í˜¸ì¶œì„ í•œ ë²ˆì— ì‹¤í–‰
        answer = rag.answer_with_llm(q, llm_call=call_openai_api)
        
        print("\n=======================================================")
        print(f"[ê¶ê¸ˆí–ˆìŠˆ(SSU) ë‹µë³€]\n{answer}")
        print("=======================================================\n")