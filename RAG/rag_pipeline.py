

from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict, Optional, Callable
import sqlite3
import os
import unicodedata
from datetime import datetime

import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
from kiwipiepy import Kiwi
from openai import OpenAI
from dotenv import load_dotenv

import requests
from bs4 import BeautifulSoup

# ------------------------------------------------------------------
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ / DB / HF ìºì‹œ / .env ì„¤ì •
# ------------------------------------------------------------------
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(ROOT_DIR, "ssu_chatbot_data.db")

HF_CACHE_DIR = os.path.join(ROOT_DIR, "hf_cache")
os.makedirs(HF_CACHE_DIR, exist_ok=True)

os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR
os.environ["SENTENCE_TRANSFORMERS_HOME"] = HF_CACHE_DIR

print("[RAG] Using DB_PATH =", DB_PATH)
print("[RAG] Using HF cache dir =", HF_CACHE_DIR)

env_path = os.path.join(ROOT_DIR, ".env")
print(f"[RAG] Loading .env from: {env_path}")

if os.path.exists(env_path):
    load_dotenv(env_path)
    print("[RAG] .env íŒŒì¼ ë¡œë“œ ì„±ê³µ")
else:
    print("[RAG] ğŸš¨ ê²½ê³ : .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

# ==========================================================
# 0. í•™ì‹ ê´€ë ¨ ìŠ¤í¬ë˜í•‘ ìœ í‹¸ (soongguri / ê¸°ìˆ™ì‚¬ ì‹ë‹¹)
# ==========================================================

SOONGGURI_URL = "https://soongguri.com/m/"
DORM_FOOD_URL = (
    "https://ssudorm.ssu.ac.kr:444/"
    "SShostel/mall_main.php?viewform=B0001_foodboard_list&board_no=1"
)


def fetch_soongguri_menu() -> str:
    """
    ìˆ­ì‹¤ëŒ€ ìƒí˜‘(soongguri.com/m)ì˜ í˜„ì¬ ì„ íƒëœ ë‚ ì§œ í•™ì‹ ë©”ë‰´ë¥¼ íŒŒì‹±í•œë‹¤.
    - HTML êµ¬ì¡°: <td class="menu_nm">ì¤‘ì‹1</td> + <td class="menu_list">ì•ˆì— ìƒì„¸ êµ¬ì„±
    """
    try:
        resp = requests.get(SOONGGURI_URL, timeout=10)
        resp.raise_for_status()
    except Exception as e:
        return f"[í•™ì‹] soongguri ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(resp.text, "html.parser")

    main_div = soup.find("div", id="mainDiv")
    if not main_div:
        return "[í•™ì‹] soongguri í˜ì´ì§€ì—ì„œ mainDivë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."

    menus: List[str] = []

    # ê° ë©”ë‰´(ì¤‘ì‹1, ì¤‘ì‹2, ì„ì‹1 ë“±)ëŠ” í•œ ì¤„(tr)ì— menu_nm / menu_list í˜•ì‹ìœ¼ë¡œ ë“¤ì–´ìˆìŒ
    for tr in main_div.find_all("tr"):
        name_td = tr.find("td", class_="menu_nm")
        list_td = tr.find("td", class_="menu_list")
        if not (name_td and list_td):
            continue

        meal_name = name_td.get_text(strip=True)  # ì˜ˆ: "ì¤‘ì‹1", "ì„ì‹1"

        # 1) ì½”ë„ˆ ì´ë¦„ (ì˜ˆ: [ëšë°°ê¸°ì½”ë„ˆ], [ë®ë°¥ì½”ë„ˆ] ë“±)
        corner = ""
        first_block = list_td.find("div")
        if first_block:
            for tag in first_block.find_all(["font", "b", "span"], recursive=True):
                text = tag.get_text(strip=True)
                if "[" in text and "]" in text:
                    corner = text
                    break

        # 2) ë©”ì¸ ë©”ë‰´ ì´ë¦„ (ì˜ˆ: â˜… ì°¨ëŒìˆœë‘ë¶€ì°Œê°œ - 5.0)
        main_dish = ""
        for tag in list_td.find_all(["font", "b", "span"], recursive=True):
            text = tag.get_text(" ", strip=True)
            if "â˜…" in text:
                main_dish = text.replace("â˜…", "").strip()
                break

        # 3) ë°˜ì°¬ / êµ¬ì„± ë©”ë‰´ë“¤ (ì‘ì€ tableì˜ tdë“¤)
        side_dishes: List[str] = []
        for td in list_td.find_all("td"):
            t = td.get_text(strip=True)
            if not t:
                continue
            if "ì•ŒëŸ¬ì§€ìœ ë°œì‹í’ˆ" in t or "ì›ì‚°ì§€" in t:
                continue
            if t == "ã€€":
                continue
            if t not in side_dishes:
                side_dishes.append(t)

        line = meal_name
        if corner:
            line += f" {corner}"
        if main_dish:
            line += f" - {main_dish}"
        if side_dishes:
            line += "\n  Â· " + "\n  Â· ".join(side_dishes)

        menus.append(line)

    if not menus:
        return "[í•™ì‹] soongguriì—ì„œ ì˜¤ëŠ˜ì˜ ë©”ë‰´ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    today_str = datetime.now().strftime("%Y-%m-%d")
    menu_text = f"[ìƒí˜‘ ì‹ë‹¹ ë©”ë‰´ - {today_str}]\n" + "\n\n".join(menus)
    return menu_text


def fetch_dorm_menu() -> str:
    """
    ìˆ­ì‹¤ëŒ€ ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì£¼ê°„ ì‹ë‹¨í‘œ(boxstyle02 í…Œì´ë¸”)ì—ì„œ 'ì˜¤ëŠ˜ ë‚ ì§œ'ì— í•´ë‹¹í•˜ëŠ”
    ì¤‘ì‹/ì„ì‹ ë©”ë‰´ë¥¼ íŒŒì‹±í•œë‹¤.
    - HTML êµ¬ì¡°:
        <table class="boxstyle02">
          <tr> (í—¤ë”)
          <tr>
            <th> <a ...>2025-11-21 (ê¸ˆ)</a> </th>
            <td>ì¡°ì‹</td>
            <td>ì¤‘ì‹</td>
            <td>ì„ì‹</td>
            <td>ì¤‘.ì„ì‹</td>
    """
    try:
        # ì¸ì¦ì„œ ê²½ê³  íšŒí”¼ìš© verify=False (í•„ìš”í•˜ë©´ Trueë¡œ ë³€ê²½ ê°€ëŠ¥)
        resp = requests.get(DORM_FOOD_URL, timeout=10, verify=False)
        resp.raise_for_status()
    except Exception as e:
        return f"[í•™ì‹] ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨: {e}"

    soup = BeautifulSoup(resp.text, "html.parser")

    table = soup.find("table", class_="boxstyle02")
    if not table:
        return "[í•™ì‹] ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´ í…Œì´ë¸”(boxstyle02)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    today = datetime.now().strftime("%Y-%m-%d")
    target_row = None

    # ì²« ë²ˆì§¸ trëŠ” í—¤ë”, ê·¸ ë‹¤ìŒë¶€í„° ì‹¤ì œ ë‚ ì§œ í–‰
    for tr in table.find_all("tr")[1:]:
        th = tr.find("th")
        if not th:
            continue
        text = th.get_text(strip=True)  # ì˜ˆ: "2025-11-21 (ê¸ˆ)"
        if today in text:
            target_row = tr
            break

    # ì˜¤ëŠ˜ ë‚ ì§œê°€ ì—†ìœ¼ë©´, ì£¼ê°„ ë©”ë‰´ ìš”ì•½ ë°˜í™˜
    if target_row is None:
        rows_text = []
        for tr in table.find_all("tr")[1:]:
            th = tr.find("th")
            if not th:
                continue
            date_text = th.get_text(strip=True)
            tds = tr.find_all("td")
            if len(tds) < 3:
                continue
            breakfast = tds[0].get_text("\n", strip=True)
            lunch = tds[1].get_text("\n", strip=True)
            dinner = tds[2].get_text("\n", strip=True)
            row_str = (
                f"{date_text}\n"
                f"  Â· ì¡°ì‹: {breakfast}\n"
                f"  Â· ì¤‘ì‹: {lunch}\n"
                f"  Â· ì„ì‹: {dinner}"
            )
            rows_text.append(row_str)

        if not rows_text:
            return "[í•™ì‹] ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì£¼ê°„ ë©”ë‰´ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return "[ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ì£¼ê°„ ë©”ë‰´]\n\n" + "\n\n".join(rows_text)

    # ì˜¤ëŠ˜ ë‚ ì§œ í–‰ì„ ì°¾ì€ ê²½ìš°
    tds = target_row.find_all("td")
    breakfast = tds[0].get_text("\n", strip=True) if len(tds) >= 1 else ""
    lunch = tds[1].get_text("\n", strip=True) if len(tds) >= 2 else ""
    dinner = tds[2].get_text("\n", strip=True) if len(tds) >= 3 else ""
    both = tds[3].get_text("\n", strip=True) if len(tds) >= 4 else ""

    date_label = target_row.find("th").get_text(strip=True)

    lines = [
        f"[ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´ - {date_label}]",
        f"Â· ì¡°ì‹: {breakfast or 'ë¯¸ìš´ì˜'}",
        f"Â· ì¤‘ì‹: {lunch or 'ë¯¸ë“±ë¡'}",
        f"Â· ì„ì‹: {dinner or 'ë¯¸ë“±ë¡'}",
    ]
    if both:
        lines.append(f"Â· ì¤‘Â·ì„ì‹: {both}")

    return "\n".join(lines)


def build_meal_context() -> str:
    """
    soongguri(ìƒí˜‘) + ê¸°ìˆ™ì‚¬ ì‹ë‹¹ ë©”ë‰´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨.
    intent == "í•™ì‹_ê²€ìƒ‰"ì¼ ë•Œ ì´ ë¬¸ìì—´ì„ LLMì— ë„˜ê¸´ë‹¤.
    """
    soongguri_text = fetch_soongguri_menu()
    dorm_text = fetch_dorm_menu()

    context_parts = [
        "ë‹¤ìŒì€ ìˆ­ì‹¤ëŒ€í•™êµ ì˜¤ëŠ˜ì˜ í•™ì‹ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤.",
        "",
        soongguri_text,
        "",
        dorm_text,
    ]
    return "\n".join(context_parts)


# =========================
# 1. Document ìŠ¤í‚¤ë§ˆ ì •ì˜
# =========================

@dataclass
class Document:
    id: str               # "notice:123", "review:45" ê°™ì€ ë‚´ë¶€ ID
    type: str             # "notice" | "review" | "club"
    text: str             # ê²€ìƒ‰ê³¼ LLM ì»¨í…ìŠ¤íŠ¸ì— ì‚¬ìš©í•  ë³¸ë¬¸
    meta: Dict[str, str]  # ë¶€ê°€ ì •ë³´ (í•™ê³¼, êµìˆ˜ëª…, ë‚ ì§œ, ë™ì•„ë¦¬ ì´ë¦„ ë“±)


# =========================
# 2. DB â†’ Document ë¡œë”
# =========================

def load_notices() -> List[Document]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    cur.execute("""
        SELECT id, title, category, post_date, status, full_body_text, link, department
        FROM notices
    """)
    rows = cur.fetchall()
    conn.close()

    docs: List[Document] = []
    for id_, title, category, post_date, status, body, link, dept in rows:
        title = title or ""
        category = category or ""
        post_date = post_date or ""
        status = status or ""
        body = body or ""
        dept = dept or "ì •ë³´ ì—†ìŒ"
        link = link or ""

        text = (
            f"[ê³µì§€] {title}\n"
            f"- ì¹´í…Œê³ ë¦¬: {category}\n"
            f"- í•™ê³¼: {dept}\n"
            f"- ê²Œì‹œì¼: {post_date}\n"
            f"- ìƒíƒœ: {status}\n\n"
            f"{body}"
        )
        meta = {
            "title": title,
            "category": category,
            "post_date": post_date,
            "status": status,
            "department": dept,
            "link": link,
        }
        docs.append(
            Document(
                id=f"notice:{id_}",
                type="notice",
                text=text,
                meta=meta,
            )
        )
    return docs


def load_reviews() -> List[Document]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    cur.execute("""
        SELECT id, subject_name, professor_name, star_rating, semester, review_text
        FROM lecture_reviews
    """)
    rows = cur.fetchall()
    conn.close()

    docs: List[Document] = []
    for id_, subj, prof, star, sem, review_text in rows:
        subj = subj or ""
        prof = prof or "ì •ë³´ ì—†ìŒ"
        sem = sem or ""
        review_text = review_text or ""
        star = star if star is not None else 0.0

        text = (
            f"[ê°•ì˜í‰] {subj} - {prof} êµìˆ˜ë‹˜\n"
            f"- ë³„ì : {star}\n"
            f"- ìˆ˜ê°• í•™ê¸°: {sem}\n\n"
            f"{review_text}"
        )
        meta = {
            "subject_name": subj,
            "professor_name": prof,
            "star_rating": str(star),
            "semester": sem,
        }
        docs.append(
            Document(
                id=f"review:{id_}",
                type="review",
                text=text,
                meta=meta,
            )
        )
    return docs


def load_clubs() -> List[Document]:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    cur.execute("""
        SELECT id, club_name, category, description, recruitment_info, source_url
        FROM clubs
    """)
    rows = cur.fetchall()
    conn.close()

    docs: List[Document] = []
    for id_, name, category, desc, recruit, url in rows:
        name = name or "ì œëª© ì—†ìŒ"
        category = category or "ë™ì•„ë¦¬"
        desc = desc or ""
        recruit = recruit or ""
        url = url or ""

        text = (
            f"[ë™ì•„ë¦¬] {name} (ë¶„ë¥˜: {category})\n"
            f"- ëª¨ì§‘ ì •ë³´: {recruit}\n"
            f"- ë§í¬: {url}\n\n"
            f"{desc}"
        )
        meta = {
            "club_name": name,
            "category": category,
            "recruitment_info": recruit,
            "source_url": url,
        }
        docs.append(
            Document(
                id=f"club:{id_}",
                type="club",
                text=text,
                meta=meta,
            )
        )
    return docs


def load_all_docs() -> List[Document]:
    notices = load_notices()
    reviews = load_reviews()
    clubs = load_clubs()
    print(
        f"[RAG] loaded notices={len(notices)}, "
        f"reviews={len(reviews)}, clubs={len(clubs)}"
    )
    return notices + reviews + clubs


# =========================
# 3. BM25 1ì°¨ ê²€ìƒ‰ê¸°
# =========================

try:
    KIWI_PROCESSOR = Kiwi()
except Exception as e:
    print(f"[ERROR] Kiwi ê°ì²´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    KIWI_PROCESSOR = None


def simple_tokenize(text: str) -> List[str]:
    """
    Kiwipiepy í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ í† í¬ë‚˜ì´ì§•.
    UnicodeDecodeError ë°©ì§€ë¥¼ ìœ„í•´ ì •ê·œí™” ë° ë°©ì–´ ì½”ë“œ í¬í•¨.
    """
    if not KIWI_PROCESSOR:
        return str(text or "").strip().split()

    if not text:
        return []

    text = str(text).strip()
    text = unicodedata.normalize("NFC", text)

    try:
        clean_text = text.encode("utf-8", "ignore").decode("utf-8")
    except Exception:
        clean_text = text

    if not clean_text:
        return []

    tokens: List[str] = []
    try:
        for token in KIWI_PROCESSOR.tokenize(clean_text, normalize_coda=True):
            if token.tag.startswith(("N", "V", "M", "SL", "SN")):
                tokens.append(token.form)
    except Exception as e:
        print(f"[Tokenize Warning] Skipped text due to error: {e}")
        return clean_text.split()

    return tokens


class BM25Retriever:
    def __init__(self, docs: List[Document]):
        self.docs = docs
        print(f"[BM25] {len(docs)}ê°œ ë¬¸ì„œ í† í°í™” ì‹œì‘...")
        self.corpus_tokens: List[List[str]] = [simple_tokenize(d.text) for d in docs]
        self.bm25 = BM25Okapi(self.corpus_tokens)
        print(f"[BM25] í† í°í™” ë° ì¸ë±ì‹± ì™„ë£Œ.")

    def search(self, query: str, top_k: int = 30) -> List[Document]:
        tokens = simple_tokenize(query)
        scores = self.bm25.get_scores(tokens)
        ranked_indices = sorted(
            range(len(self.docs)),
            key=lambda i: scores[i],
            reverse=True,
        )[:top_k]
        return [self.docs[i] for i in ranked_indices]


# =========================
# 4. ë²¡í„° ê¸°ë°˜ ì¬ì •ë ¬ê¸°
# =========================

class VectorReranker:
    def __init__(
        self,
        model_name: str = "jhgan/ko-sroberta-multitask",
    ):
        self.model = SentenceTransformer(model_name)

    @staticmethod
    def _cosine_sim(query_emb: np.ndarray, doc_embs: np.ndarray) -> np.ndarray:
        q = query_emb / (np.linalg.norm(query_emb) + 1e-12)
        d = doc_embs / (np.linalg.norm(doc_embs, axis=1, keepdims=True) + 1e-12)
        sims = d @ q
        return sims

    def rerank(self, query: str, candidates: List[Document], top_k: int = 5) -> List[Document]:
        if not candidates:
            return []

        texts = [d.text for d in candidates]
        doc_embs = self.model.encode(texts, convert_to_numpy=True)
        query_emb = self.model.encode([query], convert_to_numpy=True)[0]
        sims = self._cosine_sim(query_emb, doc_embs)

        ranked_indices = np.argsort(-sims)[:top_k]
        return [candidates[i] for i in ranked_indices]


# =========================
# 5. RAG íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
# =========================

class RAGPipeline:
    def __init__(
        self,
        docs: Optional[List[Document]] = None,
        bm25_top_k: int = 30,
        rerank_top_k: int = 5,
    ):
        self.docs = docs or load_all_docs()
        self.bm25 = BM25Retriever(self.docs)
        self.reranker = VectorReranker()
        self.bm25_top_k = bm25_top_k
        self.rerank_top_k = rerank_top_k

    def retrieve(
        self,
        query: str,
        intent: Optional[str] = None,
        slots: Optional[Dict[str, str]] = None,
    ) -> List[Document]:
        slots = slots or {}

        # 1) BM25 í›„ë³´
        candidates = self.bm25.search(query, top_k=self.bm25_top_k)

        # 2) intent/slots ê¸°ë°˜ í•„í„°
        filtered: List[Document] = candidates

        if intent == "ê°•ì˜í‰_ê²€ìƒ‰":
            filtered = [d for d in filtered if d.type == "review"]
        elif intent == "ê³µì§€_ê²€ìƒ‰":
            filtered = [d for d in filtered if d.type == "notice"]
        elif intent == "ë™ì•„ë¦¬_ê²€ìƒ‰":
            filtered = [d for d in filtered if d.type == "club"]

        prof = slots.get("professor_name") or slots.get("professor")
        if prof:
            filtered = [
                d for d in filtered
                if d.meta.get("professor_name") and prof in d.meta.get("professor_name", "")
            ]

        dept = slots.get("department")
        if dept:
            filtered = [
                d for d in filtered
                if d.meta.get("department") and dept in d.meta.get("department", "")
            ]

        club_name = slots.get("club_name")
        if club_name:
            filtered = [
                d for d in filtered
                if d.meta.get("club_name") and club_name in d.meta.get("club_name", "")
            ]

        if not filtered:
            filtered = candidates

        # 3) ë²¡í„° ê¸°ë°˜ ì¬ì •ë ¬
        final_docs = self.reranker.rerank(query, filtered, top_k=self.rerank_top_k)
        return final_docs

    def build_prompt(self, query: str, docs: List[Document]) -> (str, str):
        context_blocks = []
        for i, d in enumerate(docs, start=1):
            header = f"[ë¬¸ì„œ {i} | {d.type} | id={d.id}]"
            block = f"{header}\n{d.text}"
            context_blocks.append(block)

        context_text = "\n\n---\n\n".join(context_blocks)

        system_msg = (
            "ë„ˆëŠ” ìˆ­ì‹¤ëŒ€í•™êµ ê´€ë ¨ ì •ë³´ë§Œ ë‹µë³€í•˜ëŠ” ì±—ë´‡ì´ì•¼.\n"
            "ì•„ë˜ì— ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ì•„ì„œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.\n"
            "ëª¨ë¥´ê² ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´."
        )

        user_msg = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{query}\n\n"
            f"ë‹¤ìŒì€ ê´€ë ¨ ë¬¸ì„œë“¤ì´ì•¼. ì´ ì •ë³´ë§Œ ê·¼ê±°ë¡œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.\n\n"
            f"{context_text}"
        )

        return system_msg, user_msg

    def build_meal_prompt(self, query: str, meal_context: str) -> (str, str):
        """
        í•™ì‹ ì „ìš© í”„ë¡¬í”„íŠ¸.
        """
        system_msg = (
            "ë„ˆëŠ” ìˆ­ì‹¤ëŒ€í•™êµ í•™ì‹ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” ì±—ë´‡ì´ì•¼.\n"
            "ì•„ë˜ì— ì œê³µëœ í•™ì‹ ë©”ë‰´ ì •ë³´ë§Œ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.\n"
            "ëª¨ë¥´ê² ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´."
        )

        user_msg = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{query}\n\n"
            f"ë‹¤ìŒì€ ì˜¤ëŠ˜ í•™ì‹ ê´€ë ¨ ì •ë³´ì•¼. ì´ ì •ë³´ë§Œ ê·¼ê±°ë¡œ ë‹µë³€ì„ ë§Œë“¤ì–´ì¤˜.\n\n"
            f"{meal_context}"
        )

        return system_msg, user_msg

    def answer_with_llm(
        self,
        query: str,
        llm_call: Callable[[str, str], str],
        intent: Optional[str] = None,
        slots: Optional[Dict[str, str]] = None,
    ) -> str:
        # 1) í•™ì‹ intentë©´ RAG ëŒ€ì‹  í•™ì‹ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
        if intent == "í•™ì‹_ê²€ìƒ‰":
            meal_context = build_meal_context()
            system_msg, user_msg = self.build_meal_prompt(query, meal_context)
            answer = llm_call(system_msg, user_msg)
            return answer

        # 2) ê·¸ ì™¸ intentëŠ” RAG íë¦„
        docs = self.retrieve(query, intent=intent, slots=slots)
        system_msg, user_msg = self.build_prompt(query, docs)
        answer = llm_call(system_msg, user_msg)

        # RAGAS í‰ê°€ìš© í¬ë§·ì´ í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ ë³€í™˜í•´ì„œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • ê°€ëŠ¥
        return answer


# =========================
# 6. GPT API í˜¸ì¶œ í•¨ìˆ˜
# =========================

def call_openai_api(system_msg: str, user_msg: str) -> str:
    """
    OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    .env íŒŒì¼ì—ì„œ í‚¤ë¥¼ ë¡œë“œí•˜ë¯€ë¡œ ë³´ì•ˆìƒ ì•ˆì „í•©ë‹ˆë‹¤.
    """
    api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        return "[ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.0,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"[LLM í˜¸ì¶œ ì˜¤ë¥˜] API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# =========================
# 7. ê°„ë‹¨ í…ŒìŠ¤íŠ¸ìš© main
# =========================

if __name__ == "__main__":
    print(f"[RAG] Using DB_PATH = {DB_PATH}")

    rag = RAGPipeline()

    while True:
        try:
            q = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: ì—”í„°ë§Œ ì…ë ¥): ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if not q:
            break

        print("\n--- ğŸ§  LLMì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ---")

        # ë§¤ìš° ê°„ë‹¨í•œ intent ì˜ˆì‹œ (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” NLUì—ì„œ ë„˜ê²¨ì¤„ ê²ƒ)
        lower_q = q.lower()
        if "í•™ì‹" in q or "ë©”ë‰´" in q or "ë°¥ ë­" in q:
            intent = "í•™ì‹_ê²€ìƒ‰"
        else:
            intent = None

        answer = rag.answer_with_llm(q, llm_call=call_openai_api, intent=intent)

        print("\n=======================================================")
        print(f"[ê¶ê¸ˆí–ˆìŠˆ(SSU) ë‹µë³€]\n{answer}")
        print("=======================================================\n")