import random
import os
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail
from dotenv import load_dotenv

load_dotenv() # .env íŒŒì¼ ë¡œë“œ

def generate_code() -> str:
    """6ìë¦¬ ì¸ì¦ë²ˆí˜¸ ìƒì„± (ë³´ì•ˆ ê°•í™”ë¥¼ ìœ„í•´ 6ìë¦¬ ì¶”ì²œ)"""
    return str(random.randint(100000, 999999))

async def send_verification_email(to_email: str, code: str):
    """SendGridë¥¼ ì´ìš©í•´ ì¸ì¦ ì´ë©”ì¼ ì „ì†¡"""
    
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
    from_email = os.getenv("FROM_EMAIL")
    api_key = os.getenv("SENDGRID_API_KEY")

    if not api_key or not from_email:
        raise Exception("SENDGRID_API_KEY ë˜ëŠ” FROM_EMAIL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    message = Mail(
        from_email=from_email,
        to_emails=to_email,
        subject="[ìˆ­ì‹¤ëŒ€í•™êµ] ì¬í•™ìƒ ì´ë©”ì¼ ì¸ì¦ ì½”ë“œ",
        html_content=f"""
            <h3>ì•ˆë…•í•˜ì„¸ìš”. ìˆ­ì‹¤ëŒ€í•™êµ ì¬í•™ìƒ ì¸ì¦ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.</h3>
            <p>ì•„ë˜ 6ìë¦¬ ì¸ì¦ë²ˆí˜¸ë¥¼ ì›¹ì‚¬ì´íŠ¸ì— ì…ë ¥í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•´ ì£¼ì„¸ìš”.</p>
            <p style="font-size: 24px; font-weight: bold; color: #007bff;">ì¸ì¦ë²ˆí˜¸: {code}</p>
            <p>ì¸ì¦ë²ˆí˜¸ëŠ” 5ë¶„ê°„ ìœ íš¨í•©ë‹ˆë‹¤.</p>
        """
    )
    
    try:
        sg = SendGridAPIClient(api_key)
        response = sg.send(message)
        # print(f"SendGrid Status Code: {response.status_code}")
    except Exception as e:
        # ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹…ì„ ìœ„í•´ ì˜ˆì™¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        print(f"SendGrid ë°œì†¡ ì˜¤ë¥˜: {e}")
        raise





#ë²¡í„° ê²€ìƒ‰, bm25 êµ¬í˜„

import chromadb
import pickle
import torch
import numpy as np
from sentence_transformers import SentenceTransformer
import os

print("\n--- â³ ì±—ë´‡ ë¦¬ì†ŒìŠ¤ ë¡œë”© ì¤‘... ---")

# 1. SBERT (ë²¡í„° ê²€ìƒ‰ìš©)
try:
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    sbert_model = SentenceTransformer("jhgan/ko-sbert-nli", device=device)

    # 2. ChromaDB (ë²¡í„° ê²€ìƒ‰ìš©)
    # (ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸ í•„ìš”: ë³´í†µ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ./chroma_db)
    VECTOR_DB_PATH = "./chroma_db" 
    if not os.path.exists(VECTOR_DB_PATH) and os.path.exists("../chroma_db"):
        VECTOR_DB_PATH = "../chroma_db"

    chroma_client = chromadb.PersistentClient(path=VECTOR_DB_PATH)
    vector_collection = chroma_client.get_collection(name="ssu_knowledge_base")

    # 3. BM25 (í‚¤ì›Œë“œ ê²€ìƒ‰ìš©)
    BM25_PATH = "bm25_data.pkl"
    if not os.path.exists(BM25_PATH) and os.path.exists("../bm25_data.pkl"):
        BM25_PATH = "../bm25_data.pkl"
    elif not os.path.exists(BM25_PATH) and os.path.exists("data/bm25_data.pkl"):
        BM25_PATH = "data/bm25_data.pkl"

    with open(BM25_PATH, "rb") as f:
        bm25_data = pickle.load(f)
        bm25_engine = bm25_data["bm25"]
        bm25_docs = bm25_data["documents"]

    print("âœ… ì±—ë´‡ ì—”ì§„ ë¡œë”© ì™„ë£Œ!\n")

except Exception as e:
    print(f"âš ï¸ ì±—ë´‡ ë¡œë”© ì‹¤íŒ¨ (ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”): {e}")
    sbert_model = None


# --- ë„êµ¬ í•¨ìˆ˜ ---
def simple_tokenizer(text):
    return text.split()

# --- ê²€ìƒ‰ í•¨ìˆ˜ë“¤ ---
def search_vector(query, k=5):
    if not sbert_model: return []
    query_vec = sbert_model.encode(query).tolist()
    results = vector_collection.query(query_embeddings=[query_vec], n_results=k)
    output = []
    if results['documents']:
        for i, doc in enumerate(results['documents'][0]):
            output.append({
                "content": results['metadatas'][0][i].get("original_text", doc),
                "score": results['distances'][0][i], 
                "type": "vector"
            })
    return output

def search_bm25(query, k=5):
    if not sbert_model: return [] # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
    tokenized_query = simple_tokenizer(query)
    scores = bm25_engine.get_scores(tokenized_query)
    top_n_indexes = np.argsort(scores)[::-1][:k] 
    output = []
    for idx in top_n_indexes:
        output.append({
            "content": bm25_docs[idx],
            "score": scores[idx],
            "type": "bm25"
        })
    return output

def reciprocal_rank_fusion(results_list, k=60):
    fused_scores = {}
    for results in results_list:
        for rank, item in enumerate(results):
            content = item['content']
            if content not in fused_scores:
                fused_scores[content] = 0
            fused_scores[content] += 1 / (rank + k)
    reranked_results = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)
    return [item[0] for item in reranked_results]

# --- ìµœì¢… í˜¸ì¶œ í•¨ìˆ˜ ---
def get_hybrid_answer(query: str):
    if not sbert_model:
        return "ì„œë²„ ì˜¤ë¥˜: ì±—ë´‡ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
    # 1. ë²¡í„° + BM25 ê²€ìƒ‰
    vec_results = search_vector(query, k=5)
    bm25_results = search_bm25(query, k=5)
    
    # 2. RRF ì¬ì •ë ¬
    final_docs = reciprocal_rank_fusion([vec_results, bm25_results])[:3]
    
    # 3. ê²°ê³¼ ì¢…í•©
    context = "\n\n".join(final_docs)
    
    # (ë‚˜ì¤‘ì— ì—¬ê¸°ì— LLM ì—°ê²° ì½”ë“œë¥¼ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤)
    return f"ğŸ¤– ì§ˆë¬¸: {query}\n\nğŸ“š [ì°¾ì€ ê·¼ê±° ìë£Œ]\n{context}"